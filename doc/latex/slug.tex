% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{slug Documentation}
\date{September 16, 2014}
\release{2.0}
\author{Mark Krumholz, Robert da Silva, Michele Fumagalli, Jonathan Parra, Teddy Rendahl, Michelle Myers}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}


Contents:


\chapter{Introduction to SLUG}
\label{intro::doc}\label{intro:introduction-to-slug}\label{intro:welcome-to-slug-s-documentation}
This is a guide for users of the SLUG software package. SLUG is distributed under the terms of the \href{http://www.gnu.org/licenses/gpl.html}{GNU General Public License v. 3.0}. A copy of the license notification is included in the main SLUG directory. If you use SLUG in any published work, please cite the SLUG method paper, \href{http://adsabs.harvard.edu/abs/2012ApJ...745..145D}{da Silva, R. L., Fumagalli, M., \& Krumholz, M. R., 2012, The Astrophysical Journal, 745, 145}. A second method paper, describing the upgraded version 2 code and a set of ancillary tools, is in preparation at this time.


\section{What Does SLUG Do?}
\label{intro:what-does-slug-do}
SLUG is a stellar population synthesis (SPS) code, meaning that, for a specified stellar initial mass function (IMF), star formation history (SFH), cluster mass function (CMF), and cluster lifetime function (CLF), it predicts the spectra and photometry of both individual star clusters and the galaxies (or sub-regions of galaxies) that contain them. In this regard, SLUG operates much like any other SPS code. The main difference is that SLUG regards the IMF, SFH, CMF, and CLF as probability distributions, and the resulting stellar population as being the result of a draw from them. SLUG performs a Monte Carlo simulation to determine the PDF of the light produced by the stellar populations that are drawn from these distributions. The remainder of this section briefly describes the major conceptual pieces of a SLUG simulation. For a more detailed description, readers are referred to \href{http://adsabs.harvard.edu/abs/2012ApJ...745..145D}{da Silva, Fumagalli, \& Krumholz (2012)}.


\section{Cluster Simulations and Galaxy Simulations}
\label{intro:cluster-simulations-and-galaxy-simulations}
SLUG can simulate either a simple stellar population (i.e., a group of stars all born at one time) or a composite stellar population, consisting of stars born at a distribution of times. We refer to the former case as a ``cluster'' simulation, and the latter as a ``galaxy'' simulation, since one can be thought of as approximating the behavior of a single star cluster, and the other as approximating a whole galaxy.


\section{Probability Distribution Functions: the IMF, SFH, CMF, and CLF}
\label{intro:probability-distribution-functions-the-imf-sfh-cmf-and-clf}\label{intro:ssec-slugpdfs}
As mentioned above, SLUG regards the IMF, SFH, CMF, and CLF as probability distribution functions. These PDFs can be described by a very wide range of possible functional forms; see {\hyperref[pdfs:sec-pdfs]{\emph{Probability Distribution Functions}}} for details on the exact functional forms allowed, and on how they can be specified in the code. When SLUG runs a cluster simulation, it draws stars from the specified IMF in an attempt to produce a cluster of a user-specified total mass. There are a number of possible methods for performing such mass-limited sampling, and SLUG gives the user a wide menu of options; see {\hyperref[pdfs:sec-pdfs]{\emph{Probability Distribution Functions}}}.

For a galaxy simulation, the procedure involves one extra step. In this case, SLUG assumes that some fraction \(f_c\) of the stars in the galaxy are born in star clusters, which, for the purposes of SLUG, means that they all share the same birth time. The remaining fraction \(1-f_c\) of stars are field stars. When a galaxy simulation is run, SLUG determines the total mass of stars \(M_*\) that should have formed since the start of the simulation (or since the last output, if more than one output is requested) from the star formation history, and then draws field stars and star clusters in an attempt to produce masses \((1-f_c)M_*\) and \(f_c M_*\). For the field stars, the stellar masses are drawn from the IMF, in a process completely analogous to the cluster case. For star clusters, the masses of the clusters are drawn from the CMF, and each cluster is then populated from the IMF as in the cluster case. For both the field stars and the star clusters, the time of their birth is drawn from the PDF describing the SFH.

Finally, star clusters can be disrupted independent of the fate of their parent stars. When each cluster is formed, it is assigned a lifetime drawn from the CLF. Once that time has passed, the cluster ceases to be entered in the lists of individual cluster spectra and photometry (see next section), although the individual stars continue to contribute to the integrated light of the galaxy.


\section{Spectra and Photometry}
\label{intro:ssec-spec-phot}\label{intro:spectra-and-photometry}
Once SLUG has drawn a population of stars, its final step is to compute the light they produce. SLUG does this in several steps. First, it computes the physical properties of all the stars present user-specified times using a set of stellar evolutionary tracks. Second, it uses these physical properties to compute the composite spectra produced by the stars, using a user-specified set of stellar atmosphere models. Formally, the quantity computed is the specific luminosity per unit wavelength \(L_\lambda\). Third and finally, it computes photometry for the stellar population by integrating the computed spectra over a set of specified photometric filters. Depending on the options specified by the user and the filter under consideration, the photometric value output will be one of the following:
\begin{itemize}
\item {} 
The frequency-averaged luminosity across the filter, defined as

\end{itemize}
\begin{gather}
\begin{split}\langle L_\nu\rangle_R = \frac{\int L_\nu \, d\ln\nu}{\int R_\nu (\nu/\nu_c)^\beta \, d\ln\nu},\end{split}\notag
\end{gather}
where \(L_\nu\) is the specific luminosity per unit frequency, \(R_\nu\) is the filter response function per photon at frequency \(\nu\), \(\nu_c\) is the central wavelength of the filter, and \(\beta\) is a constant that is defined by convention for each filter, and is either 0, 1, or 2; usually it is 0 for optical and UV filters.
\begin{itemize}
\item {} 
The wavelength-averaged luminosity across the filter, defined as

\end{itemize}

where \(L_\lambda\) is the specific luminosity per unit wavelength, \(R_\lambda\) is the filter response function per photon at wavelength \(\lambda\), and \(\lambda_c\) is the central wavelength of the filter.
\begin{itemize}
\item {} 
The AB magnitude, defined by

\end{itemize}
\begin{gather}
\begin{split}M_{\rm AB} = -2.5 \log_{10} \left[\frac{\langle L_\nu\rangle_R}{4\pi\left(10\,\mathrm{pc}\right)^2}\right] - 48.6,\end{split}\notag
\end{gather}
where \(\langle L_\nu\rangle_R\) is in units of erg s:math:\emph{\textasciicircum{}\{-1\}} Hz:math:\emph{\textasciicircum{}\{-1\}}.
\begin{itemize}
\item {} 
The ST magnitude, defined by

\end{itemize}
\begin{gather}
\begin{split}M_{\rm ST} = -2.5 \log_{10} \left[\frac{\langle L_\lambda\rangle_R}{4\pi\left(10\,\mathrm{pc}\right)^2}\right] - 21.1,\end{split}\notag
\end{gather}
where \(\langle L_\lambda\rangle_R\) is in units of erg s:math:\emph{\textasciicircum{}\{-1\}} AA:math:\emph{\textasciicircum{}\{-1\}}.
\begin{itemize}
\item {} 
The Vega magnitude, defined by

\end{itemize}
\begin{gather}
\begin{split}M_{\rm Vega} = M_{\rm AB} - M_{\rm AB}(\mbox{Vega}),\end{split}\notag
\end{gather}
where \(M_{\rm AB}(\mbox{Vega})\) is the AB magnitude of Vega. The latter quantity is computed on the fly, using a stored Kurucz model spectrum for Vega.
\begin{itemize}
\item {} 
The photon flux above some threshold \(\nu_0\), defined as

\end{itemize}
\begin{gather}
\begin{split}Q(\nu_0) = \int_{\nu_0}^\infty \frac{L_\nu}{h\nu} \, d\nu.\end{split}\notag
\end{gather}\begin{itemize}
\item {} 
The bolometric luminosity,

\end{itemize}
\begin{gather}
\begin{split}L_{\rm bol} = \int_0^\infty L_\nu \, d\nu.\end{split}\notag
\end{gather}
For a cluster simulation, this procedure is applied to the star cluster being simulated at a user-specified set of output times. For a galaxy simulation, the procedure is much the same, but it can be done both for all the stars in the galaxy taken as a whole, and individually for each star cluster that is still present (i.e., that has not been disrupted).


\section{Monte Carlo Simulation}
\label{intro:monte-carlo-simulation}
The steps described in the previous two section are those required for a single realization of the stellar population. However, the entire point of SLUG is to repeat this procedure many times in order to build up the statistics of the population light output. Thus the entire procedure can be repeated as many times as the user desires.


\chapter{Compiling and Installing SLUG}
\label{compiling::doc}\label{compiling:compiling-and-installing-slug}

\section{Dependencies}
\label{compiling:dependencies}
The core SLUG program requires
\begin{itemize}
\item {} 
The \href{http://www.boost.org/}{Boost C++ libraries}

\item {} 
The \href{http://www.gnu.org/software/gsl/}{GNU scientific library}

\item {} 
The \href{http://heasarc.gsfc.nasa.gov/fitsio/fitsio.html}{cfitsio library} (optional, only required for FITS capabilities)

\end{itemize}

Compilation will be easiest if you install these libraries such that the header files are included in your \code{CXX\_INCLUDE\_PATH} and the compiled object files are in your \code{LD\_LIBRARY\_PATH}. Alternately, you can manually specify the locations of these files by editing the Makefiles -- see below. The cfitsio library is optional, and is only required if you want the ability to write FITS output. To compile without it, use the flag \code{FITS=DISABLE\_FITS} when calling \code{make} (see below). Note that SLUG uses some Boost libraries that must be built separately (see the Boost documentation on how to build and install Boost libraries).

In addition to the core dependencies, slugpy, the python helper library requires:
\begin{itemize}
\item {} 
\href{http://www.numpy.org/}{numpy}

\item {} 
\href{http://www.scipy.org/}{scipy}

\item {} 
\href{http://www.astropy.org/}{astropy} (optional, only required for FITS capabilities)

\end{itemize}


\section{Compiling}
\label{compiling:compiling}
If you have boost, GSL, and (if you're using it) cfitsio included in your \code{CXX\_INCLUDE\_PATH} and \code{LD\_LIBRARY\_PATH} environment variables, and your system is running either MacOSX or Linux, you should be able to compile simply by doing:

\begin{Verbatim}[commandchars=\\\{\}]
make
\end{Verbatim}

from the main \code{slug} directory. To compile in debug mode, do:

\begin{Verbatim}[commandchars=\\\{\}]
make debug
\end{Verbatim}

instead. To compile without cfitsio, do:

\begin{Verbatim}[commandchars=\\\{\}]
make FITS=DISABLE\PYGZus{}FITS
\end{Verbatim}

Alternately, you can manually specify the compiler flags to be used by creating a file named \code{Make.mach.MACHINE\_NAME} in the \code{src} directory, and then doing:

\begin{Verbatim}[commandchars=\\\{\}]
make MACHINE=MACHINE\PYGZus{}NAME
\end{Verbatim}

An example machine-specific file, \code{src/Make.mach.ucsc-hyades} is included in the repository. You can also override or reset any compilation flag you want by editing the file \code{src/Make.config.override}.

Finally, note that SLUG is written in C++11, and requires some C++11 features, so it may not work with older C++ compilers. The following compiler versions are known to work: gcc \textgreater{}= 4.8 (4.7 works on most but not all platforms), clang/llvm \textgreater{}= 3.3, icc \textgreater{}= 14.0. Earlier versions may work as well, but no guarantees.


\chapter{Running a SLUG simulation}
\label{running::doc}\label{running:running-a-slug-simulation}
Once SLUG is compiled, running a simulation is extremely simple. The first step, which is not required but makes life a lot simpler, is to set the environment variable \code{SLUG\_DIR} to the directory where you have installed SLUG. If you are using a \code{bash}-like shell, the syntax for this is:

\begin{Verbatim}[commandchars=\\\{\}]
export SLUG\PYGZus{}DIR = /path/to/slug
\end{Verbatim}

while for a \code{csh}-like shell, it is:

\begin{Verbatim}[commandchars=\\\{\}]
setenv SLUG\PYGZus{}DIR /path/to/slug
\end{Verbatim}

This is helpful because SLUG needs a lot of input data, and if you don't set this variable, you will have to manually specify where to find it.

Next, to run on a single processor, just do:

\begin{Verbatim}[commandchars=\\\{\}]
./bin/slug param/filename.param
\end{Verbatim}

where \code{filename.param} is the name of a parameter file, formatted as specified in {\hyperref[parameters:sec-parameters]{\emph{Parameter Specification}}}. The code will write a series of output files as described in {\hyperref[output:sec-output]{\emph{Output Files and Format}}}.

If you have more than one core at your disposal, you can also run SLUG in parallel, using the command line:

\begin{Verbatim}[commandchars=\\\{\}]
python ./bin/slug.py param/filename.param
\end{Verbatim}

This called a python script that automatically divides up the Monte Carlo trials you have requested between the available processors, then consolidates the output so that it looks the same as if you had run a single-processor job. The python script allows fairly fine-grained control of the parallelism. It accepts the following command line arguments:
\begin{itemize}
\item {} 
\code{-n NPROC, -{-}nproc NPROC}: this parameter specifies the number of simultaneous SLUG processes to run. It defaults to the number of cores present on the machine where the code is running

\item {} 
\code{-b BATCHSIZE, -{-}batchsize BATCHSIZE}: this specifies how to many trials to do per SLUG process. It defaults to the total number of trials requested divided by the total number of processes, rounded up, so that only one SLUG process is run per processor. \emph{Rationale}: The default behavior is optimal from the standpoint of minimizing the overhead associated with reading data from disk, etc. However, if you are doing a very large number of runs that are going to require hours, days, or weeks to complete, and you probably want the code to checkpoint along the way. In that case it is probably wise to set this to a value smaller than the default in order to force output to be dumped periodically.

\item {} 
\code{-nc, -{-}noconsolidate}: by default the \code{slug.py} script will take all the outputs produced by the parallel runs and consolidate them into single output files, matching what would have been produced had the code been run in serial mode. If set, this flag suppresses that behavior, and instead leaves the output as a series of files whose root names match the model name given in the parameter file, plus the extension \code{\_pPPPPP\_nNNNNN}, where the digits \code{PPPPP} give the number of the processor that produces that file, and the digits \code{NNNNN} give the run number on that processor. \emph{Rationale}: normally consolidation is convenient. However, if the output is very large, this may produce undesirably bulky files. Furthermore, if one is doing a very large number of simulations over an extended period, and the \code{slug.py} script is going to be run multiple times (e.g.due to wall clock limits on a cluster), it may be preferable to leave the files unconsolidated until all runs have been completed.

\end{itemize}


\chapter{Parameter Specification}
\label{parameters:sec-parameters}\label{parameters::doc}\label{parameters:parameter-specification}

\section{File Format}
\label{parameters:file-format}
An example parameter file is included as \code{param/example.param} in the source tree. Parameter files for SLUG are generically formatted as a series of entries of the form:

\begin{Verbatim}[commandchars=\\\{\}]
keyword    value
\end{Verbatim}

Any line starting with \code{\#} is considered to be a comment and is ignored, and anything on a line after a \code{\#} is similarly treated as a comment and ignored. Some general rules on keywords are:
\begin{itemize}
\item {} 
Keywords may appear in any order.

\item {} 
Some keywords have default values, indicated in parenthesis in the list below. These keywords are optional and need not appear in the parameter file. All others are required.

\item {} 
Keywords and values are case-insensitive.

\item {} 
Unless explicitly stated otherwise, units for mass are always \(M_\odot\), units for time are always yr.

\item {} 
Any time a file or directory is specified, if it is given as a relative rather than absolute path, it is assumed to be relative to the environment variable \code{\$SLUG\_DIR}. If this environment variable is not set, it is assumed to be relative to the current working directory.

\end{itemize}

The keywords recognized by SLUG can be categorized as described in the remainder of this section.


\section{Basic Keywords}
\label{parameters:basic-keywords}\label{parameters:ssec-basic-keywords}
These specify basic data for the run.
\begin{itemize}
\item {} 
\code{model\_name} (default: \code{SLUG\_DEF}): name of the model. This will become the base filename for the output files.

\item {} 
\code{out\_dir} (default: \code{output}): name of the directory into which output should be written.

\item {} 
\code{verbosity} (default: \code{1}): level of verbosity when running, with 0 indicating no output, 1 indicating some output, and 2 indicating a great deal of output.

\end{itemize}


\section{Simulation Control Keywords}
\label{parameters:simulation-control-keywords}
These control the operation of the simulation.
\begin{itemize}
\item {} 
\code{sim\_type} (default: \code{galaxy}): set to \code{galaxy} to run a galaxy simulation (a composite stellar population), or to \code{cluster} to run a cluster simulation (a simple stellar population)

\item {} 
\code{n\_trials} (default: \code{1}): number of trials to run

\item {} 
\code{log\_time} (default: \code{0}): set to 1 for logarithmic time step, 0 for linear time steps

\item {} 
\code{time\_step}: size of the time step. If \code{log\_time} is set to 0, this is in yr. If \code{log\_time} is set to 1, this is in dex (i.e., a value of 0.2 indicates that every 5 time steps correspond to a factor of 10 increase in time).

\item {} 
\code{start\_time}: first output time. This may be omitted if \code{log\_time} is set to 0, in which case it defaults to a value equal to \code{time\_step}.

\item {} 
\code{end\_time}: last output time, in yr. Note that not all the tracks include entries going out to times \textgreater{}1 Gyr, and the results will become inaccurate if the final time is larger than the tracks allow.

\item {} 
\code{sfr}: star formation rate. Only used if \code{sim\_type} is \code{galaxy}; for \code{cluster}, it will be ignored, and can be omitted. If, instead of specifying a numerical value for this parameter, you specify the string \code{sfh}, the code will interpret this as a flag that a star formation history should be read from the file specified by the \code{sfh} keyword.

\item {} 
\code{sfh}: name of star formation history file. This file is a PDF file, formatted as described in {\hyperref[pdfs:sec-pdfs]{\emph{Probability Distribution Functions}}}. This is ignored, and can be omitted, if \code{sim\_type} is \code{cluster}, or if \code{sfr} is not set to \code{sfh}.

\item {} 
\code{cluster\_mass}: mass of the star cluster for simulations with \code{sim\_type} set to \code{cluster}. This can be omitted, and will be ignored, if \code{sim\_type} is \code{galaxy}.

\item {} 
\code{redshift} (default: \code{0}): place the system at the specified redshift. The computed spectra and photometry will then be computed in the observed rather than the rest frame of the system.

\end{itemize}


\section{Output Control Keywords}
\label{parameters:output-control-keywords}
These control what quantities are computed and written to disk. Full a full description of the output files and how they are formatted, see {\hyperref[output:sec-output]{\emph{Output Files and Format}}}.
\begin{itemize}
\item {} 
\code{out\_cluster} (default: \code{1}): write out the physical properties of star clusters? Set to 1 for yes, 0 for no.

\item {} 
\code{out\_cluster\_phot} (default: \code{1}): write out the photometry of star clusters? Set to 1 for yes, 0 for no.

\item {} 
\code{out\_cluster\_spec} (default: \code{1}): write out the spectra of star clusters? Set to 1 for yes, 0 for no.

\item {} 
\code{out\_integrated} (default: \code{1}): write out the integrated physical properties of the whole galaxy? Set to 1 for yes, 0 for no. This keyword is ignored if \code{sim\_type} is \code{cluster}.

\item {} 
\code{out\_integrated\_phot} (default: \code{1}): write out the integrated photometry of the entire galaxy? Set to 1 for yes, 0 for no. This keyword is ignored if \code{sim\_type} is \code{cluster}.

\item {} 
\code{out\_integrated\_spec} (default: \code{1}): write out the integrated spectra of the entire galaxy? Set to 1 for yes, 0 for no. This keyword is ignored if \code{sim\_type} is \code{cluster}.

\item {} 
\code{output\_mode} (default: \code{ascii}): set to \code{ascii}, \code{binary}, or \code{fits}. Selecting \code{ascii} causes the output to be written in ASCII text, which is human-readable, but produces much larger files. Selecting \code{binary} causes the output to be written in raw binary. Selecting \code{fits} causes the output to be written FITS format. This will be somewhat larger than raw binary output, but the resulting files will be portable between machines, which the raw binary files are not guaranteed to be. All three output modes can be read by the python library, though with varying speed -- ASCII output is slowest, FITS is intermediate, and binary is fastest.

\end{itemize}


\section{Physical Model Keywords}
\label{parameters:ssec-phys-keywords}\label{parameters:physical-model-keywords}
These specify the physical models to be used for stellar evolution, atmospheres, the IMF, etc.
\begin{itemize}
\item {} \begin{description}
\item[{\code{imf} (default: \code{lib/imf/chabrier.imf}): name of the IMF descriptor file; this is a PDF file, formatted as described in {\hyperref[pdfs:sec-pdfs]{\emph{Probability Distribution Functions}}}. Note that SLUG ships with the following IMF files pre-defined (in the directory \code{lib/imf})}] \leavevmode\begin{itemize}
\item {} 
\code{chabrier.imf} (single-star IMF from \href{http://adsabs.harvard.edu/abs/2005ASSL..327...41C}{Chabrier, 2005, in ``The Initial Mass Function 50 Years Later'', eds. E. Corbelli, F. Palla, \& H. Zinnecker, Springer: Dordrecht, p. 41})

\item {} 
\code{chabrier03.imf} (single-star IMF from \href{http://adsabs.harvard.edu/abs/2003PASP..115..763C}{Chabrier, 2003, PASP, 115, 763-795})

\item {} 
\code{kroupa.imf} (IMF from \href{http://adsabs.harvard.edu/abs/2002Sci...295...82K}{Kroupa, 2002, Science, 295, 82-91})

\item {} 
\code{kroupa\_sb99.imf} (simplified version of the Kroupa, 2002 IMF used by default by \href{http://www.stsci.edu/science/starburst99/docs/default.htm}{starburst99})

\item {} 
\code{salpeter.imf} (single-component power law IMF from \href{http://adsabs.harvard.edu/abs/1955ApJ...121..161S}{Salpeter, 1955, ApJ, 121, 161})

\end{itemize}

\end{description}

\item {} 
\code{cmf} (default: \code{lib/cmf/slug\_default.cmf}): name of the CMF descriptor file; this is a PDF file, formatted as described in {\hyperref[pdfs:sec-pdfs]{\emph{Probability Distribution Functions}}}. The default selection is a power law \(dN/dM \propto M^{-2}\) from \(M = 10^2 - 10^7\;M_\odot\). This is ignored, and may be omitted, if \code{sim\_type} is set to \code{cluster}.

\item {} 
\code{clf} (default: \code{lib/clf/slug\_default.clf}): name of the CLF descriptor file; this is a PDF file, formatted as described in {\hyperref[pdfs:sec-pdfs]{\emph{Probability Distribution Functions}}}. The default gives a power law distribution of lifetimes \(t\) with \(dN/dt\propto t^{-1.9}\) from 1 Myr to 1 Gyr. Note that this corresponds to a cluster age distribution of slope -0.9. The SLUG source also ships with an alternative CLF file, \code{lib/clf/nodisrupt.clf}, which disables cluster disruption entirely (by setting the lifetime distribution to a \(\delta\) function at \(10^{300}\) yr).

\item {} \begin{description}
\item[{\code{tracks} (default: \code{lib/tracks/Z0140v00.txt}): stellar evolution tracks to use. The following tracks ship with SLUG (all in the directory \code{lib/tracks}):}] \leavevmode\begin{itemize}
\item {} 
\code{ZXXXXvYY.txt}: Geneva (2013) tracks; metallicities are Solar (\code{XXXX = 0140}) and 1/7 Solar (\code{XXXX = 0020}), and rotation rates are 0 (\code{YY = 00}) and 40\% of breakup (\code{YY = 40}).

\item {} 
\code{modcXXX.dat}: Geneva tracks with standard mass loss, for metallicities of \(2\times\) Solar (\code{040}), Solar (\code{020}), \(0.4\times\) Solar (\code{008}), \(0.2\times\) Solar (\code{004}), and \(0.05\times\) Solar (\code{001}).

\item {} 
\code{modeXXX.dat}: same as \code{modcXXX.dat}, but with higher mass loss rates.

\item {} 
\code{modpXXX.dat}: Padova tracks with thermally pulsing AGB stars; metallicities use the same scale as \code{modcXXX.dat} files (i.e., \code{020} is Solar).

\item {} 
\code{modsXXX.dat}: same as \code{modpXXX.dat}, but without thermally pulsing AGB stars

\end{itemize}

\end{description}

\item {} 
\code{atmospheres} (default: \code{lib/atmospheres}): directory where the stellar atmosphere library is located. Note that file names are hard-coded, so if you want to use different atmosphere models with a different format, you will have to write new source code to do so.

\item {} \begin{description}
\item[{\code{specsyn\_mode} (default: \code{sb99}): spectral synthesis mode. Allowed values are:}] \leavevmode\begin{itemize}
\item {} 
\code{planck}: treat all stars as black bodies

\item {} 
\code{Kurucz}: use Kurucz atmospheres, as compiled by \href{http://adsabs.harvard.edu/abs/1997A\%26AS..125..229L}{Lejeune et al. (1997, A\&AS, 125, 229)}, for all stars

\item {} 
\code{Kurucz+Hillier}: use Kurucz atmospheres for all stars except Wolf-Rayet stars; WR stars use Hillier model atmospheres (\href{http://adsabs.harvard.edu/abs/1998ApJ...496..407H}{Hillier \& Miller, 1998, ApJ, 496, 407})

\item {} 
\code{Kurucz+Pauldrach}: use Kurucz atmospheres for all stars except OB stars; OB stars use Pauldrach model atmospheres (\href{http://adsabs.harvard.edu/abs/2001A\%26A...375..161P}{Pauldrach et al., 2001, A\&A, 375, 161})

\item {} 
\code{SB99}: emulate the behavior of \code{starburst99}: use Pauldrach for OB stars, Hillier for WR stars, and Kurucz for all other stars

\end{itemize}

\end{description}

\item {} 
\code{clust\_frac} (default: \code{1.0}): fraction of stars formed in clusters

\item {} 
\code{min\_stoch\_mass} (default: \code{0.0}): minimum stellar mass to be treated stochastically. All stars with masses below this value are assumed to be sampled continuously from the IMF.

\item {} 
\code{metallicity}: metallicity of the stellar population, relative to solar. This may be omitted if \code{tracks} is set to one of the default sets of tracks that ships with SLUG, as the metallicities for these tracks are hardwired in. This keyword is provided to allow users to supply their own tracks.

\item {} 
\code{WR\_mass}: minimum starting mass that stars must have in order to pass through a Wolf-Rayet phase. This can be omitted if \code{tracks} is set to one of the default sets of tracks that ships with SLUG, as the WR cutoff masses for these tracks are hardwired in. This keyword is provided to allow users to supply their own tracks.

\end{itemize}


\section{Photometric Filter Keywords}
\label{parameters:ssec-phot-keywords}\label{parameters:photometric-filter-keywords}
These describe the photometry to be computed. Note that none of these keywords have any effect unless \code{out\_integrated\_phot} or \code{out\_cluster\_phot} is set to 1.
\begin{itemize}
\item {} \begin{description}
\item[{\code{phot\_bands}: photometric bands for which photometry is to be computed. The values listed here can be comma- or whitespace-separated. For a list of available photometric filters, see the file \code{lib/filters/FILTER\_LIST}. In addition to these filters, SLUG always allows four special ``bands'':}] \leavevmode\begin{itemize}
\item {} 
\code{QH0}: the \(\mathrm{H}^0\) ionizing luminosity, in photons/sec

\item {} 
\code{QHe0}: the \(\mathrm{He}^0\) ionizing luminosity, in photons/sec

\item {} 
\code{QHe1}: the \(\mathrm{He}^+\) ionizing luminosity, in photons/sec

\item {} 
\code{Lbol}: the bolometric luminosity, in \(L_\odot\)

\end{itemize}

\end{description}

\item {} 
\code{filters} (default: \code{lib/filters}): directory containing photometric filter data

\item {} \begin{description}
\item[{\code{phot\_mode} (default: \code{L\_nu}): photometric system to be used when writing photometric outputs. Full definitions of the quantities computed for each of the choices listed below are given in {\hyperref[intro:ssec-spec-phot]{\emph{Spectra and Photometry}}}. Note that these values are ignored for the four special bands \code{QH0}, \code{QHe0}, \code{QHe1}, and \code{Lbol}. These four bands are always written out in the units specified above. Allowed values are:}] \leavevmode\begin{itemize}
\item {} 
\code{L\_nu}: report frequency-averaged luminosity in the band, in units of erg/s/Hz

\item {} 
\code{L\_lambda}: report wavelength-averaged luminosity in the band, in units of erg/s/Angstrom

\item {} 
\code{AB}: report AB magnitude

\item {} 
\code{STMAG}: report ST magnitude

\item {} 
\code{VEGA}: report Vega magnitude

\end{itemize}

\end{description}

\end{itemize}


\chapter{Probability Distribution Functions}
\label{pdfs:probability-distribution-functions}\label{pdfs::doc}\label{pdfs:sec-pdfs}
The SLUG code regards the IMF, the CMF, the CLF, and the SFH as probability distribution functions -- see {\hyperref[intro:ssec-slugpdfs]{\emph{Probability Distribution Functions: the IMF, SFH, CMF, and CLF}}}. The code provides a generic file format through which PDFs can be specified. Examples can be found in the \code{lib/imf}, \code{lib/cmf}, \code{lib/clf}, and \code{lib/sfh} directories of the SLUG distribution.

PDFs in SLUG are generically written as functions
\begin{gather}
\begin{split}\frac{dp}{dx} = n_1 f_1(x; x_{1,a}, x_{1,b}) + n_2 f_2(x; x_{2,a}, x_{2,b}) + n_3 f_3(x; x_{3,a}, x_{3,b}) + \cdots,\end{split}\notag
\end{gather}
where \(f_i(x; x_{i,a}, x_{i,b})\) is non-zero only for \(x \in [x_{i,a}, x_{i,b}]\). The functions \(f_i\) are simple continuous functional forms, which we refer to as \emph{segments}. Functions in this form can be specified in SLUG in two ways.


\section{Basic Mode}
\label{pdfs:basic-mode}
The most common way of specifying a PDF is in basic mode. Basic mode describes a PDF that has the properties that
\begin{enumerate}
\item {} 
the segments are contiguous with one another, i.e., \(x_{i,b} = x_{i+1,a}\)

\item {} 
\(n_i f_i(x_{i,b}; x_{i,a}, x_{i,b}) = n_{i+1} f_{i+1}(x_{i+1,a}; x_{i+1,a}, x_{i+1,b})\)

\item {} 
the overall PDF is normalized such that \(\int (dp/dx)\, dx = 1\)

\end{enumerate}

Given these constraints, the PDF can be specified fully simply by giving the \(x\) values that define the edges of the segments and the functional forms \(f\) of each segment; the normalizations can be computed from the constraint equations. Note that SFH PDFs cannot be described using basic mode, because they are not normalized to unity. Specifying a non-constant SFH requires advanced mode.

An example of a basic mode PDF file is as follows:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}
\PYGZsh{} This is an IMF definition file for SLUG v2.
\PYG{g+gh}{\PYGZsh{} This file defines the Chabrier (2005) IMF}
\PYG{g+gh}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}

\PYGZsh{} Breakpoints: mass values where the functional form changes
\PYGZsh{} The first and last breakpoint will define the minimum and
\PYGZsh{} maximum mass
breakpoints 0.08 1 120

\PYGZsh{} Definitions of segments between the breakpoints

\PYGZsh{} This segment is a lognormal with a mean of log\PYGZus{}10 (0.2 Msun)
\PYGZsh{} and dispersion 0.55; the dispersion is in log base 10, not
\PYGZsh{} log base e
segment
type lognormal
mean 0.2
disp 0.55

\PYGZsh{} This segment is a powerlaw of slope \PYGZhy{}2.35
segment
type powerlaw
slope \PYGZhy{}2.35
\end{Verbatim}

This example represents a \href{http://adsabs.harvard.edu/abs/2005ASSL..327...41C}{Chabrier (2005)} IMF from \(0.08 - 120\) \(M_\odot\), which is of the functional form
.. math:: frac\{dp\}\{dm\} propto left\{begin\{array\}\{ll\} exp{[}-log(m/m\_0)\textasciicircum{}2/(2sigma\textasciicircum{}2){]} (m/m\_b)\textasciicircum{}\{-1\} , \& m \textless{} m\_b \textbackslash{} exp{[}-log(m\_b/m\_0)\textasciicircum{}2/(2sigma\textasciicircum{}2){]} (m/m\_b)\textasciicircum{}\{-2.35\}, \& m geq m\_b end\{array\} right.,
where \(m_0 = 0.2\) \(M_\odot\), \(\sigma = 0.55\), and \(m_b = 1\) \(M_\odot\).

Formally, the format of a basic mode file is as follows. Any line beginning with \code{\#} is a comment and is ignored. The first non-empty, non-comment line in a basic mode PDF file must be of the form:

\begin{Verbatim}[commandchars=\\\{\}]
breakpoints x1 x2 x3 ...
\end{Verbatim}

where \code{x1}, \code{x2}, \code{x3}, \code{...} are a non-decreasing series of real numbers. These represent the breakpoints that define the edges of the segment, in units of \(M_\odot\). In the example given above, the breakpoints are are \(0.08\), \(1\), and \(120\), indicating that the first segment goes from \(0.08 - 1\) \(M_\odot\), and the second from \(1 - 120\) \(M_\odot\).

After the \code{breakpoints} line, there must be a series of entries of the form:

\begin{Verbatim}[commandchars=\\\{\}]
segment
type TYPE
key1 VAL1
\PYG{g+gh}{key2 VAL2}
\PYG{g+gh}{...}
\end{Verbatim}

where \code{TYPE} specifies what functional form describes the segment, and \code{key1 VAL1}, \code{key2 VAL2}, etc. are a series of (key, value) pairs the define the free parameters for that segment. In the example above, the first segment is described as having a \code{lognormal} functional form, and the keywords \code{mean} and \code{disp} specify that the lognormal has a mean of 0.2 \(M_\odot\) and a dispersion of 0.55 in \(\log_{10}\). The second segment is of type \code{powerlaw}, and it has a slope of \(-2.35\). The full list of allowed segment types and the keywords that must be specified with them are listed in the {\hyperref[pdfs:tab-segtypes]{\emph{Segment Types}}} Table. Keywords and segment types are case-insensitive. Where more than one keyword is required, the order is arbitrary.

The total number of segments must be equal to one less than the number of breakpoints, so that each segment is described. Note that it is not necessary to specify a normalization for each segment, as the segments will be normalized relative to one another automatically so as to guarantee that the overall function is continuous.
\phantomsection\label{pdfs:tab-segtypes}

\begin{threeparttable}
\capstart\caption{Segment Types}

\begin{tabulary}{\linewidth}{|L|L|L|L|L|L|}
\hline
\textsf{\relax 
Name
} & \textsf{\relax 
Functional form
} & \textsf{\relax 
Keyword
} & \textsf{\relax 
Meaning
} & \textsf{\relax 
Keyword
} & \textsf{\relax 
Meaning
}\\
\hline
\code{delta}
 & 
\(\delta(x-x_a)\)
 &  &  &  & \\

\code{exponential}
 & 
\(\exp(-x/x_*)\)
 & 
\code{scale}
 & 
Scale length, \(x_*\)
 &  & \\

\code{lognormal}
 & 
\(x^{-1} \exp[-\log_{10}(x/x_0)^2/2\sigma^2]\)
 & 
\code{mean}
 & 
Mean, \(x_0\)
 & 
\code{disp}
 & 
Dispersion in \(\log_{10}\), \(\sigma\)
\\

\code{normal}
 & 
\(\exp[-(x-x_0)^2/2\sigma^2]\)
 & 
\code{mean}
 & 
Mean, \(x_0\)
 & 
\code{disp}
 & 
Dispersion, \(\sigma\)
\\

\code{powerlaw}
 & 
\(x^p\)
 & 
\code{slope}
 & 
Slope, \(p\)
 &  & \\

\code{schechter}
 & 
\(x^p \exp(-x/x_*)\)
 & 
\code{slope}
 & 
Slope, \(p\)
 & 
\code{xstar}
 & 
Cutoff, \(x_*\)
\\
\hline\end{tabulary}

\end{threeparttable}



\section{Advanced Mode}
\label{pdfs:advanced-mode}
In advanced mode, one has complete freedom to set all the parameters describing the PDF: the endpoints of each segment \(x_{i,a}\) and \(x_{i,b}\), the normalization of each segment \(n_i\), and the functional forms of each segment \(f_i\). This can be used to defined PDFs that are non-continuous, or that are overlapping; the latter option can be used to construct segments with nearly arbitrary functional forms, by constructing a Taylor series approximation to the desired functional form and then using a series of overlapping \code{powerlaw} segments to implement that series.

An example of an advanced mode PDF file is as follows:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}
\PYGZsh{} This is a SFH definition file for SLUG v2.
\PYGZsh{} This defines a SF history consisting of a series of
\PYGZsh{} exponentially\PYGZhy{}decaying bursts with a period of 100 Myr and
\PYGZsh{} a decay timescale of 10 Myr, with an amplitude chosen to
\PYG{g+gh}{\PYGZsh{} give a mean SFR of 10\PYGZca{}\PYGZhy{}3 Msun/yr.}
\PYG{g+gh}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}

\PYGZsh{} Declare that this is an advanced mode file
advanced

\PYGZsh{} First exponential burst
segment
type exponential
min      0.0
max      1.0e8         \PYGZsh{} Go to 100 Myr
weight   1.0e5         \PYGZsh{} Form 10\PYGZca{}5 Msun of stars over 100 Myr
scale    1.0e7         \PYGZsh{} Decay time 10 Myr

\PYGZsh{} Next 4 bursts
segment
type exponential
min      1.0e8
max      2.0e8
weight   1.0e5
scale    1.0e7

segment
type exponential
min      2.0e8
max      3.0e8
weight   1.0e5
scale    1.0e7

segment
type exponential
min      3.0e8
max      4.0e8
weight   1.0e5
scale    1.0e7

segment
type exponential
min      4.0e8
max      5.0e8
weight   1.0e5
scale    1.0e7
\end{Verbatim}

This represents a star formation history that is a series of exponential bursts, separated by 100 Myr, with decay times of 10 Myr. Formally, this SFH follows the functional form
.. math:: dot\{M\}\_* = n e\textasciicircum{}\{-(t,mathrm\{mod\}, P)/t\_\{rm dec\}\},
where \(P = 100\) Myr is the period and \(t_{\rm dec} = 10\) Myr is the decay time, from times \(0-500\) Myr. The normalization constant \(n\) is set by the condition that \((1/P) \int_0^P \dot{M}_* \,dt / = 0.001\) \(M_\odot\;\mathrm{yr}^{-1}\), i.e., that the mean SFR averaged over a single burst period is 0.001 \(M_\odot\;\mathrm{yr}^{-1}\).

Formally, the format of an advanced mode file is as follows. First, all advanced mode files must start with the line:

\begin{Verbatim}[commandchars=\\\{\}]
advanced
\end{Verbatim}

to declare that the file is in advanced mode. After that, there must be a series of entries of the form:

\begin{Verbatim}[commandchars=\\\{\}]
segment
type TYPE
min MIN
max MAX
weight WEIGHT
key1 VAL1
\PYG{g+gh}{key2 VAL2}
\PYG{g+gh}{...}
\end{Verbatim}

The \code{type} keyword is exactly the same as in basic mode, as are the segment-specific parameter keywords \code{key1}, \code{key2}, \(\ldots\). The same functional forms, listed in the {\hyperref[pdfs:tab-segtypes]{\emph{Segment Types}}} Table, are available as in basic mode. The additional keywords that must be supplied in advanced mode are \code{min}, \code{max}, and \code{weight}. The \code{min} and \code{max} keywords give the upper and lower limits \(x_{i,a}\) and \(x_{i,b}\) for the segment; the probability is zero outside these limits. The keyword \code{weight} specifies the integral under the segment, i.e., the weight \(w_i\) given for segment \(i\) is used to set the normalization \(n_i\) via the equation
.. math:: w\_i = n\_i int\_\{x\_\{i,a\}\}\textasciicircum{}\{x\_\{i,b\}\} f\_i(x) , dx.
In the case of a star formation history, as in the example above, the weight \(w_i\) of a segment is simply the total mass of stars formed in that segment. In the example given above, the first segment declaration sets up a PDF that with a minimum at 0 Myr, a maximum at 100 Myr, following an exponential functional form with a decay time of \(10^7\) yr. During this time, a total mass of \(10^5\) \(M_\odot\) of stars is formed.

Note that, for the IMF, CMF, and CLF, the absolute values of the weights to not matter, only their relative values. On the other hand, for the SFH, the absolute weight does matter.


\section{Sampling Methods}
\label{pdfs:sampling-methods}
A final option allowed in both basic and advanced mode is a specification of the sampling method. The sampling method is a description of how to draw a population of objects from the PDF, when the population is specified as having a total sum \(M_{\rm target}\) (usually but not necessarily a total mass) rather than a total number of members \(N\); there are a number of ways to do this, which do not necessarily yield identical distributions, even for the same underlying PDF. To specify a sampling method, simply add the line:

\begin{Verbatim}[commandchars=\\\{\}]
method METHOD
\end{Verbatim}

to the PDF file. This line can appear anywhere except inside a \code{segment} specification, or before the \code{breakpoints} or \code{advanced} line that begins the file. The following values are allowed for \code{METHOD} (case-insensitive, as always):
\begin{itemize}
\item {} 
\code{stop\_nearest}: this is the default option: draw until the total mass of the population exceeds \(M_{\rm target}\). Either keep or exclude the final star drawn depending on which choice brings the total mass closer to the target value.

\item {} 
\code{stop\_before}: same as \code{stop\_nearest}, but the final object drawn is always excluded.

\item {} 
\code{stop\_after}: same as \code{stop\_nearest}, but the final object drawn is always kept.

\item {} 
\code{stop\_50}: same as \code{stop\_nearest}, but keep or exclude the final object with 50\% probability regardless of which choice gets closer to the target.

\item {} 
\code{number}: draw exactly \(N = M_{\rm target}/\langle M\rangle\) object, where \(\langle M\rangle\) is the expectation value for a single draw.

\item {} 
\code{poisson}: draw exactly \(N\) objects, where the value of \(N\) is chosen from a Poisson distribution with expectation value \(\langle N \rangle = M_{\rm target}/\langle M\rangle\)

\item {} 
\code{sorted\_sampling}: this method was introduced by \href{http://adsabs.harvard.edu/abs/2006MNRAS.365.1333W}{Weidner \& Kroupa (2006, MNRAS. 365, 1333)}, and proceeds in steps. One first draws exactly \(N= M_{\rm target}/\langle M\rangle\) as in the \code{number} method. If the resulting total mass \(M_{\rm pop}\) is less than \(M_{\rm target}\), the procedure is repeated recursively using a target mass \(M_{\rm target} - M_{\rm pop}\) until \(M_{\rm pop} > M_{\rm target}\). Finally, one sorts the resulting stellar list from least to most massive, and then keeps or removes the final, most massive star using a \code{stop\_nearest} policy.

\end{itemize}

See the file \code{lib/imf/wk06.imf} for an example of a PDF file with a \code{method} specification.


\chapter{Output Files and Format}
\label{output:output-files-and-format}\label{output::doc}\label{output:sec-output}
SLUG can produce 7 output files, though the actual number produced depends on the setting for the \code{out\_*} keywords in the parameter file. The only file that is always produced is the summary file, which is named \code{MODEL\_NAME\_summary.txt}, where \code{MODEL\_NAME} is the value given by the \code{model\_name} keyword in the parameter file. This file contains some basic summary information for the run, and is always formatted as ASCII text regardless of the output format requested.

The other six output files all have names of the form \code{MODEL\_NAME\_xxx.ext}, where the extension \code{.ext} is one of \code{.txt}, \code{.bin}, or \code{.fits} depending on the \code{output\_mode} specified in the parameter file, and \code{xxx} is \code{integrated\_prop}, \code{integrated\_spec}, \code{integrated\_phot}, \code{cluster\_prop}, \code{cluster\_spec}, or \code{cluster\_phot}. The production of these output files is controlled by the parameters \code{out\_integrated}, \code{out\_integrated\_spec}, \code{out\_integrated\_phot}, \code{out\_cluster}, \code{out\_cluster\_spec}, and \code{out\_cluster\_phot} in the parameter file. The files are formatted as described below.

The following conventions are used throughout, unless noted otherwise:
\begin{itemize}
\item {} 
Masses are in \(M_\odot\)

\item {} 
Times in year

\item {} 
Wavelengths are in Angstrom

\item {} 
Specific luminosities are in erg/s/Angstrom

\item {} 
For \code{binary} outputs, variable types refer to C++ types

\end{itemize}


\section{The \texttt{integrated\_prop} File}
\label{output:the-integrated-prop-file}
This file contains data on the bulk physical properties of the galaxy as a whole. It consists of a series of entries containing the following fields:
\begin{itemize}
\item {} 
\code{Time}: evolution time at which the output is produced

\item {} 
\code{TargetMass}: target mass of stars in the galaxy up that time, if the IMF and SFH were perfectly sampled

\item {} 
\code{ActualMass}: actual mass of stars produced in the galaxy up to that time; generally not exactly equal to \code{TargetMass} due to finite sampling of the IMF and SFH

\item {} 
\code{LiveMass}: actual mass of stars produced in the galaxy up to that time, and which have not yet reached the end of their lives (as marked by the final entry in the stellar evolution tracks)

\item {} 
\code{ClusterMass}: actual mass of stars produced in the galaxy up to that time that are still members of non-disrupted clusters

\item {} 
\code{NumClusters}: number of non-disrupted clusters present in the galaxy at this time

\item {} 
\code{NumDisClust}: number of disrupted clusters present in the galaxy at this time

\item {} 
\code{NumFldStars}: number of field stars present in the galaxy at this time; this count only includes those stars being treated stochastically (see the parameter \code{min\_stoch\_mass} in {\hyperref[parameters:ssec-phys-keywords]{\emph{Physical Model Keywords}}})

\end{itemize}

If \code{output\_mode} is \code{ascii}, these data are output in a series of columns, with different trials separated by lines of dashes. If \code{output\_mode} is \code{fits}, the data are stored as a FITS binary table extension, with one column for each of the variables above, plus an additional column giving the trial number for that entry. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

For \code{binary} output, the file consists of a series of records containing the following variables
\begin{itemize}
\item {} 
\code{Time} (\code{double})

\item {} 
\code{TargetMass} (\code{double})

\item {} 
\code{ActualMass} (\code{double})

\item {} 
\code{LiveMass} (\code{double})

\item {} 
\code{ClusterMass} (\code{double})

\item {} 
\code{NumClusters} (\code{std::vector\textless{}double\textgreater{}::size\_type}, usually \code{unsigned long long})

\item {} 
\code{NumDisClust} (\code{std::vector\textless{}double\textgreater{}::size\_type}, usually \code{unsigned long long})

\item {} 
\code{NumFldStars} (\code{std::vector\textless{}double\textgreater{}::size\_type}, usually \code{unsigned long long})

\end{itemize}

There is one record of this form for each output time, with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial.


\section{The \texttt{integrated\_spec} File}
\label{output:the-integrated-spec-file}
This file contains data on the spectra of the entire galaxy, and consists of a series of entries containing the following fields:
\begin{itemize}
\item {} 
\code{Time}: evolution time at which the output is produced

\item {} 
\code{Wavelength}: observed frame wavelength at which the spectrum is evaluated

\item {} 
\code{L\_lambda}: specific luminosity at the specified wavelength

\end{itemize}

If \code{output\_mode} is \code{ascii}, these data are output in a series of columns, with different trials separated by lines of dashes. If \code{output\_mode} is \code{fits}, the output FITS file has two binary table extensions. The first table contains a single field listing the wavelengths at which the spectra are given. The second table has three fields, giving the trial number, the time, and the spectrum \code{L\_lambda} at that time. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

For binary output, the file is formatted as follows. The file starts with
\begin{itemize}
\item {} 
\code{NWavelength} (\code{std::vector\textless{}double\textgreater{}::size\_type}, usually \code{unsigned long long}): the number of wavelength entries in the spectra

\item {} 
\code{Wavelength} (\code{NWavelength} entries of type \code{double})

\end{itemize}

and then contains a series of records in the format
\begin{itemize}
\item {} 
\code{Time} (\code{double})

\item {} 
\code{L\_lambda} (\code{NWavelength} entries of type \code{double})

\end{itemize}

There is one such record for each output time, with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial.


\section{The \texttt{integrated\_phot} File}
\label{output:the-integrated-phot-file}
This file contains data on the photometric properties of the entire galaxy, and consists of a series of entries containing the following fields:
\begin{itemize}
\item {} 
\code{Time}: evolution time at which the output is produced

\item {} 
\code{PhotFilter1}: photometric value through filter 1, where filters follow the order in which they are specified by the \code{phot\_bands} keyword; units depend on the value of \code{phot\_mode} (see {\hyperref[parameters:ssec-phot-keywords]{\emph{Photometric Filter Keywords}}})

\item {} 
\code{PhotFilter2}

\item {} 
\code{PhotFilter3}

\item {} 
\code{...}

\end{itemize}

If \code{output\_mode} is \code{ascii}, these data are output in a series of columns, with different trials separated by lines of dashes. If \code{output\_mode} is \code{fits}, the data are stored as a series of columns in a binary table extension to the FITS file; the filter names and units are included in the header information for the columns. In addition to the time and photometric filter values, the FITS file contains a column specifying the trial number for that entry. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

For binary output, the file is formatted as follows. The file starts with
\begin{itemize}
\item {} 
\code{NFilter} (stored as \code{ASCII text}): number of filters used

\item {} 
\code{FilterName} \code{FilterUnit} (\code{NFilter} entries stored as \code{ASCII text}): the name and units for each filter are listed in ASCII, one filter-unit pair per line

\end{itemize}

This is followed by a series of entries of the form
\begin{itemize}
\item {} 
\code{Time} (\code{double})

\item {} 
\code{PhotFilter} (\code{NFilter} entries of type \code{double})

\end{itemize}

There is one such record for each output time, with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial.


\section{The \texttt{cluster\_prop} File}
\label{output:the-cluster-prop-file}
This file contains data on the bulk physical properties of the non-disrupted star clusters in the galaxy, with one entry per cluster per time at which that cluster exists. Each entry contains the following fields
\begin{itemize}
\item {} 
\code{UniqueID}: a unique identifier number for each cluster that is preserved across times and output files

\item {} 
\code{Time}: evolution time at which the output is produced

\item {} 
\code{FormTime}: time at which that cluster formed

\item {} 
\code{Lifetime}: amount of time from birth to when the cluster will disrupt

\item {} 
\code{TargetMass}: target mass of stars in the cluster, if the IMF were perfectly sampled

\item {} 
\code{BirthMass}: actual mass of stars present in the cluster at formation

\item {} 
\code{LiveMass}: actual mass of stars produced in the cluster at this output time that have not yet reached the end of their lives (as marked by the final entry in the stellar evolution tracks)

\item {} 
\code{NumStar}: number of living stars in the cluster at this time; this count only includes those stars being treated stochastically (see the parameter \code{min\_stoch\_mass} in {\hyperref[parameters:ssec-phys-keywords]{\emph{Physical Model Keywords}}})

\item {} 
\code{MaxStarMass}: mass of most massive star still living in the cluster; this only includes those stars being treated stochastically (see the parameter \code{min\_stoch\_mass} in {\hyperref[parameters:ssec-phys-keywords]{\emph{Physical Model Keywords}}})

\end{itemize}

If \code{output\_mode} is \code{ascii}, these data are output in a series of columns, with different trials separated by lines of dashes. If \code{output\_mode} is \code{fits}, the data are stored as a FITS binary table extension, with one column for each of the variables above, plus an additional column giving the trial number for that entry. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

For \code{binary} output, the file consists of a series of records, one for each output time, with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial. Each record consists of a header containing
\begin{itemize}
\item {} 
\code{Time} (\code{double})

\item {} 
\code{NCluster} (\code{std::vector\textless{}double\textgreater{}::size\_type}, usually \code{unsigned long long}): number of non-disrupted clusters present at this time

\end{itemize}

This is followed by \code{NCluster} entries of the following form:
\begin{itemize}
\item {} 
\code{UniqueID} (\code{unsigned long})

\item {} 
\code{FormationTime} (\code{double})

\item {} 
\code{Lifetime} (\code{double})

\item {} 
\code{TargetMass} (\code{double})

\item {} 
\code{BirthMass} (\code{double})

\item {} 
\code{LiveMass} (\code{double})

\item {} 
\code{NumStar} (\code{std::vector\textless{}double\textgreater{}::size\_type}, usually \code{unsigned long long})

\item {} 
\code{MaxStarMass} (\code{double})

\end{itemize}


\section{The \texttt{cluster\_spec} File}
\label{output:the-cluster-spec-file}
This file contains the spectra of the individual clusters, and each entry contains the following fields:
\begin{itemize}
\item {} 
\code{UniqueID}: a unique identifier number for each cluster that is preserved across times and output files

\item {} 
\code{Time}: evolution time at which the output is produced

\item {} 
\code{Wavelength}: observed frame wavelength at which the spectrum is evaluated

\item {} 
\code{L\_lambda}: specific luminosity at the specified wavelength

\end{itemize}

If \code{output\_mode} is \code{ascii}, these data are output in a series of columns, with different trials separated by lines of dashes. If \code{output\_mode} is \code{fits}, the output FITS file has two binary table extensions. The first table contains a single field listing the wavelengths at which the spectra are given. The second table has four fields, giving the trial number, the unique ID of the cluster, the time, and the spectrum \code{L\_lambda}. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

Output in \code{binary} mode is formatted as follows.  The file starts with
\begin{itemize}
\item {} 
\code{NWavelength} (\code{std::vector\textless{}double\textgreater{}::size\_type}, usually \code{unsigned long long}): the number of wavelength entries in the spectra

\item {} 
\code{Wavelength} (\code{NWavelength} entries of type \code{double})

\end{itemize}

and then contains a series of records, one for each output time , with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial. Each record consists of a header containing
\begin{itemize}
\item {} 
\code{Time} (\code{double})

\item {} 
\code{NCluster} (\code{std::vector\textless{}double\textgreater{}::size\_type}, usually \code{unsigned long long}): number of non-disrupted clusters present at this time

\end{itemize}

This is followed by \code{NCluster} entries of the following form:
\begin{itemize}
\item {} 
\code{UniqueID} (\code{unsigned long})

\item {} 
\code{L\_lambda} (\code{NWavelength} entries of type \code{double})

\end{itemize}


\section{The \texttt{cluster\_phot} File}
\label{output:the-cluster-phot-file}
This file contains the photometric values for the individual clusters. Each entry contains the following fields:
\begin{itemize}
\item {} 
\code{UniqueID}: a unique identifier number for each cluster that is preserved across times and output files

\item {} 
\code{Time}: evolution time at which the output is produced

\item {} 
\code{PhotFilter1}: photometric value through filter 1, where filters follow the order in which they are specified by the \code{phot\_bands} keyword; units depend on the value of \code{phot\_mode} (see {\hyperref[parameters:ssec-phot-keywords]{\emph{Photometric Filter Keywords}}})

\item {} 
\code{PhotFilter2}

\item {} 
\code{PhotFilter3}

\item {} 
\code{...}

\end{itemize}

If \code{output\_mode} is \code{ascii}, these data are output in a series of columns, with different trials separated by lines of dashes. If \code{output\_mode} is \code{fits}, the data are stored as a series of columns in a binary table extension to the FITS file; the filter names and units are included in the header information for the columns. In addition to the time, unique ID, and photometric filter values, the FITS file contains a column specifying the trial number for that entry. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

In \code{binary} output mode, the binary data file starts with
\begin{itemize}
\item {} 
\code{NFilter} (stored as \code{ASCII text}): number of filters used

\item {} 
\code{FilterName} \code{FilterUnit} (\code{NFilter} entries stored as \code{ASCII text}): the name and units for each filter are listed in ASCII, one filter-unit pair per line

\end{itemize}

and then contains a series of records, one for each output time , with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial. Each record consists of a header containing
\begin{itemize}
\item {} 
\code{Time} (\code{double})

\item {} 
\code{NCluster} (\code{std::vector\textless{}double\textgreater{}::size\_type}, usually \code{unsigned long long}): number of non-disrupted clusters present at this time

\end{itemize}

This is followed by \code{NCluster} entries of the following form:
\begin{itemize}
\item {} 
\code{UniqueID} (\code{unsigned long})

\item {} 
\code{PhotFilter} (\code{NFilter} entries of type \code{double})

\end{itemize}


\chapter{Filters and Filter Data}
\label{filters:sec-filters}\label{filters::doc}\label{filters:filters-and-filter-data}
SLUG comes with a fairly extensive list of filters, adapted from the list maintained by Charlie Conroy as part of \href{https://code.google.com/p/fsps/}{fsps}. However, users may wish to add additional filters, and so the format of the filter list is documented here for convenience.

Filter data is stored in two ASCII text files, \code{FILTER\_LIST} and \code{allfilters.dat}, which are stored in the \code{lib/filters} directory. The \code{FILTER\_LIST} file is an index listing the available filters. In consists of five whitespace-separated columns. The first column is just an numerical index. The second is the name of the filter; this is the name that should be entered in the \code{phot\_bands} keyword (see {\hyperref[parameters:ssec-phot-keywords]{\emph{Photometric Filter Keywords}}}) to request photometry in that filter. The third and fourth columns the value of \(\beta\) and \(\lambda_c\) (the central wavelength) for that filter -- see {\hyperref[intro:ssec-spec-phot]{\emph{Spectra and Photometry}}} for definitions. Anything after the fourth column is regarded as a comment, and can be used freely for a description of that filter.

The \code{allfilters.dat} file contains the filter responses. The file contains a series of entires for different filters, each delineated by a header line that begins with \code{\#}. The order in which filters appear in this file matches that in which they appear in the \code{FILTER\_LIST}. After the header line, are a series of lines each containing two numbers. The first is the wavelength in Angstrom, and the second is the filter response function at that wavelength.


\chapter{slugpy -- The Python Helper Library}
\label{slugpy:slugpy-the-python-helper-library}\label{slugpy:sec-slugpy}\label{slugpy::doc}

\section{Basic Usage}
\label{slugpy:basic-usage}
SLUG comes with the python module slugpy, which contains an extensive set of routines for reading, writing, and manipulating SLUG outputs. The most common task is to read a set of SLUG outputs into memory so that they can be processed. To read the data from a SLUG run using slugpy, one can simply do the following:

\begin{Verbatim}[commandchars=\\\{\}]
from slugpy import *
idata = read\PYGZus{}integrated(\PYGZsq{}SLUG\PYGZus{}MODEL\PYGZus{}NAME\PYGZsq{})
cdata = read\PYGZus{}cluster(\PYGZsq{}SLUG\PYGZus{}MODEL\PYGZus{}NAME\PYGZsq{})
\end{Verbatim}

The \code{read\_integrated} function reads all the integrated-light data (i.e., the data stored in the \code{\_integrated\_*} files -- see {\hyperref[output:sec-output]{\emph{Output Files and Format}}}) for a SLUG output whose name is given as the argument. This is the base name specified by the \code{model\_name} keyword (see {\hyperref[parameters:ssec-basic-keywords]{\emph{Basic Keywords}}}), without any extensions; the slugpy library will automatically determine which outputs are available and in what format, and read the appropriate files. It returns a \code{namedtuple} containing all the output data available for that simulation. The \code{read\_cluster} function is analogous, except that instead of reading the whole-galaxy data, it reads data on the individual star clusters, as stored in the \code{\_cluster\_*} output files.


\section{Full Documentation}
\label{slugpy:full-documentation}\label{slugpy:module-slugpy}\index{slugpy (module)}\index{combine\_cluster() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.combine_cluster}\pysiglinewithargsret{\code{slugpy.}\bfcode{combine\_cluster}}{\emph{data}}{}
Function to combine cluster data from multiple SLUG2 runs,
treating each input run as a separate set of trials. Trial and
cluster unique ID numbers are altered as necessary to avoid
duplication between the merged data sets.
\begin{description}
\item[{Parameters:}] \leavevmode\begin{description}
\item[{data}] \leavevmode{[}list\_like{]}
A list containing the cluster data for each run, as
returned by read\_cluster

\end{description}

\item[{Returns:}] \leavevmode\begin{description}
\item[{combined\_data}] \leavevmode{[}namedtuple{]}
The combined data, in the same format as each object in data

\end{description}

\end{description}

\end{fulllineitems}

\index{combine\_integrated() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.combine_integrated}\pysiglinewithargsret{\code{slugpy.}\bfcode{combine\_integrated}}{\emph{data}}{}
Function to combine integrated data from multiple SLUG2 runs,
treating each input run as a separate set of trials.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{data}] \leavevmode{[}list\_like{]}
A list containing the integrated data for each run, as
returned by read\_integrated

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{combined\_data}] \leavevmode{[}namedtuple{]}
The combined data, in the same format as each object in data

\end{description}

\end{description}

\end{fulllineitems}

\index{compute\_photometry() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.compute_photometry}\pysiglinewithargsret{\code{slugpy.}\bfcode{compute\_photometry}}{\emph{wl}, \emph{spec}, \emph{filtername}, \emph{photsystem='L\_nu'}, \emph{filter\_wl=None}, \emph{filter\_response=None}, \emph{filter\_beta=None}, \emph{filter\_wl\_c=None}, \emph{filter\_dir=None}}{}
This function takes an input spectrum and a set of response
functions for photometric filters, and returns the photometry
through those filters.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{wl}] \leavevmode{[}array{]}
Wavelength of input spectrum in Angstrom

\item[{spec}] \leavevmode{[}array{]}
Specific luminosity per unit wavelength for input spectrum, in
erg/s/A

\item[{filtername}] \leavevmode{[}string or iterable of strings{]}
Name or list of names of the filters to be used. Filter names
can also include the special filters Lbol, QH0, QHe0, and QHe1;
the values returned for these will be the bolometric luminosity
(in erg/s) and the photon luminosities (in photons/s) in the H,
He, and He+ ionizing-continua, respectively.

\item[{photsystem}] \leavevmode{[}string{]}
The photometric system to use for the output. Allowable values
are `L\_nu', `L\_lambda', `AB', `STMAG', and `Vega',
corresponding to the options defined in the SLUG code.

\item[{filter\_wl}] \leavevmode{[}array or iterable of arrays{]}
Array giving the wavelengths in Angstrom at which the filter is
response function is given. If this object is an iterable of
arrays rather than a single array, it is assumed to represent
the wavelengths for a set of filters. If this is set,
no data is read from disk. Default behavior is to read the
filter information from disk.

\item[{filter\_response}] \leavevmode{[}array or iterable of arrays{]}
Array giving the filter response function at each wavelenght
and for each filter in filter\_wl. Must be set if filter\_wl is
set, ignored otherwise.

\item[{filter\_beta}] \leavevmode{[}iterable{]}
Array-like object containing the index beta for each
filter. Must be set if filter\_wl is set, ignored otherwise.

\item[{filter\_wl\_c}] \leavevmode{[}iterable{]}
Array-like object containing the pivot wavelength for each
filter. Must be set if filter\_wl is set, ignored otherwise.

\item[{filter\_dir}] \leavevmode{[}string{]}
Directory where the filter data files can be found. If left as
None, filters will be looked for in the \$SLUG\_DIR/lib/filters
directory. This parameter is used only if filtername is not
None.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{phot}] \leavevmode{[}array{]}
Photometric values in the requested filters. Units depend on
the choice of photometric system:
L\_nu --\textgreater{} erg/s/Hz;
L\_lambda --\textgreater{} erg/s/A;
AB --\textgreater{} absolute AB magnitude;
STMAG --\textgreater{} absolute ST magnitude;
Vega --\textgreater{} absolute Vega magnitude;

\end{description}

\end{description}

\end{fulllineitems}

\index{photometry\_convert() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.photometry_convert}\pysiglinewithargsret{\code{slugpy.}\bfcode{photometry\_convert}}{\emph{photsystem}, \emph{phot}, \emph{units}, \emph{wl\_cen=None}, \emph{filter\_last=False}}{}
Function to convert photometric data between photometric systems.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{photsystem}] \leavevmode{[}string{]}
The photometric system to which to convert. Allowable values
are `L\_nu', `L\_lambda', `AB', `STMAG', and `Vega',
corresponding to the options defined in the SLUG code. If this
is set and the conversion requested involves a conversion from
a wavelength-based system to a frequency-based one, wl\_cen must
not be None.

\item[{phot}] \leavevmode{[}array{]}
array of photometric data; if the array has more than one
dimension, the first dimension is assumed to represent the
different photometric filters

\item[{units}] \leavevmode{[}iterable of strings{]}
iterable listing the units of the input photometric data. On
return, strings will be changed to the units of the new system.

\item[{wl\_cen}] \leavevmode{[}array{]}
central wavelengths of the filters, in Angstrom; can be left as
None if the requested conversion doesn't require going between
wavelength- and frequency-based systems.

\item[{filter\_last}] \leavevmode{[}bool{]}
If the input data have more than one dimension, by default it
is assumed that the first dimension contains values for the
different photometric filters. If this keyword is set to True,
it will instead be assumed that the last dimension contains the
values for the different filters.

\end{description}

\item[{Returns}] \leavevmode
Nothing

\item[{Raises}] \leavevmode
ValueError, if wl\_cen is None but the requested conversion
requires going between wavelength- and frequency-based systems

\end{description}

\end{fulllineitems}

\index{read\_cluster() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.read_cluster}\pysiglinewithargsret{\code{slugpy.}\bfcode{read\_cluster}}{\emph{model\_name}, \emph{output\_dir=None}, \emph{fmt=None}, \emph{nofilterdata=False}, \emph{photsystem=None}, \emph{verbose=False}, \emph{read\_info=None}}{}
Function to read all cluster data for a SLUG2 run.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{model\_name}] \leavevmode{[}string{]}
The name of the model to be read

\item[{output\_dir}] \leavevmode{[}string{]}
The directory where the SLUG2 output is located; if set to None,
the current directory is searched, followed by the SLUG\_DIR
directory if that environment variable is set

\item[{fmt}] \leavevmode{[}string{]}
Format for the file to be read. Allowed values are `ascii',
`bin' or `binary, and `fits'. If one of these is set, the code
will only attempt to open ASCII-, binary-, or FITS-formatted
output, ending in .txt., .bin, or .fits, respectively. If set
to None, the code will try to open ASCII files first, then if
it fails try binary files, and if it fails again try FITS
files.

\item[{nofilterdata}] \leavevmode{[}bool{]}
If True, the routine does not attempt to read the filter
response data from the standard location

\item[{photsystem}] \leavevmode{[}None or string{]}
If photsystem is None, the data will be returned in the same
photometric system in which they were read. Alternately, if it
is a string, the data will be converted to the specified
photometric system. Allowable values are `L\_nu', `L\_lambda',
`AB', `STMAG', and `Vega', corresponding to the options defined
in the SLUG code. If this is set and the conversion requested
involves a conversion from a wavelength-based system to a
frequency-based one, nofilterdata must be False so that the
central wavelength of the photometric filters is available.

\item[{verbose}] \leavevmode{[}bool{]}
If True, verbose output is printed as code runs

\item[{read\_info}] \leavevmode{[}dict{]}
On return, this dict will contain the keys `prop\_name',
`phot\_name', `spec\_name', `cloudyspec\_name', `cloudylines\_name'
and `format', giving the names of the files read and the format
they were in; `format' will be one of `ascii', `binary', or
`fits'. If one of the files is not present, the corresponding
\_name key will be omitted from the dict.

\end{description}

\item[{Returns}] \leavevmode
A namedtuple containing the following fields:

(Always present)
\begin{description}
\item[{id}] \leavevmode{[}array, dtype uint{]}
unique ID of cluster

\item[{trial: array, dtype uint}] \leavevmode
which trial was this cluster part of

\item[{time}] \leavevmode{[}array{]}
time at which cluster's properties are being evaluated

\end{description}

(Present if the run being read contains a cluster\_prop file)
\begin{description}
\item[{form\_time}] \leavevmode{[}array{]}
time when cluster formed

\item[{lifetime}] \leavevmode{[}array{]}
time at which cluster will disrupt

\item[{target\_mass}] \leavevmode{[}array{]}
target cluster mass

\item[{actual\_mass}] \leavevmode{[}array{]}
actual mass at formation

\item[{live\_mass}] \leavevmode{[}array{]}
mass of currently living stars

\item[{num\_star}] \leavevmode{[}array, dtype ulonglong{]}
number of living stars in cluster being treated stochastically

\item[{max\_star\_mass}] \leavevmode{[}array{]}
mass of most massive living star in cluster

\end{description}

(Present if the run being read contains a cluster\_spec file)
\begin{description}
\item[{wl}] \leavevmode{[}array{]}
wavelength, in Angstrom

\item[{spec}] \leavevmode{[}array, shape (N\_cluster, N\_wavelength){]}
specific luminosity of each cluster at each wavelength, in erg/s/A

\end{description}

(Present if the run being read contains a cluster\_phot file)
\begin{description}
\item[{filter\_names}] \leavevmode{[}list of string{]}
a list giving the name for each filter

\item[{filter\_units}] \leavevmode{[}list of string{]}
a list giving the units for each filter

\item[{filter\_wl\_cen}] \leavevmode{[}list{]}
central wavelength of each filter; this is set to None for the
filters Lbol, QH0, QHe0, and QHe1; omitted if nofilterdata is
True

\item[{filter\_wl}] \leavevmode{[}list of arrays{]}
a list giving the wavelength table for each filter; this is
None for the filters Lbol, QH0, QHe0, and QHe1; omitted if
nofilterdata is True

\item[{filter\_response}] \leavevmode{[}list of arrays{]}
a list giving the photon response function for each filter;
this is None for the filters Lbol, QH0, QHe0, and QHe1; omitted
if nofilterdata is True

\item[{phot}] \leavevmode{[}array, shape (N\_cluster, N\_filter){]}
photometric value in each filter for each cluster; units are as
indicated in the units field

\end{description}

\item[{Raises}] \leavevmode
IOError, if no photometry file can be opened
ValueError, if photsystem is set to an unknown values

\end{description}

\end{fulllineitems}

\index{read\_cluster\_phot() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.read_cluster_phot}\pysiglinewithargsret{\code{slugpy.}\bfcode{read\_cluster\_phot}}{\emph{model\_name}, \emph{output\_dir=None}, \emph{fmt=None}, \emph{nofilterdata=False}, \emph{photsystem=None}, \emph{verbose=False}, \emph{read\_info=None}}{}
Function to read a SLUG2 cluster\_phot file.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{model\_name}] \leavevmode{[}string{]}
The name of the model to be read

\item[{output\_dir}] \leavevmode{[}string{]}
The directory where the SLUG2 output is located; if set to None,
the current directory is searched, followed by the SLUG\_DIR
directory if that environment variable is set

\item[{fmt}] \leavevmode{[}string{]}
Format for the file to be read. Allowed values are `ascii',
`bin' or `binary, and `fits'. If one of these is set, the code
will only attempt to open ASCII-, binary-, or FITS-formatted
output, ending in .txt., .bin, or .fits, respectively. If set
to None, the code will try to open ASCII files first, then if
it fails try binary files, and if it fails again try FITS
files.

\item[{nofilterdata}] \leavevmode{[}bool{]}
If True, the routine does not attempt to read the filter
response data from the standard location

\item[{photsystem}] \leavevmode{[}None or string{]}
If photsystem is None, the data will be returned in the same
photometric system in which they were read. Alternately, if it
is a string, the data will be converted to the specified
photometric system. Allowable values are `L\_nu', `L\_lambda',
`AB', `STMAG', and `Vega', corresponding to the options defined
in the SLUG code. If this is set and the conversion requested
involves a conversion from a wavelength-based system to a
frequency-based one, nofilterdata must be False so that the
central wavelength of the photometric filters is available.

\item[{verbose}] \leavevmode{[}bool{]}
If True, verbose output is printed as code runs

\item[{read\_info}] \leavevmode{[}dict{]}
On return, this dict will contain the keys `fname' and
`format', giving the name of the file read and the format it
was in; `format' will be one of `ascii', `binary', or `fits'

\end{description}

\item[{Returns}] \leavevmode
A namedtuple containing the following fields:
\begin{description}
\item[{id}] \leavevmode{[}array, dtype uint{]}
unique ID of cluster

\item[{trial: array, dtype uint}] \leavevmode
which trial was this cluster part of

\item[{time}] \leavevmode{[}array{]}
times at which cluster spectra are output, in yr

\item[{filter\_names}] \leavevmode{[}list of string{]}
a list giving the name for each filter

\item[{filter\_units}] \leavevmode{[}list of string{]}
a list giving the units for each filter

\item[{filter\_wl\_eff}] \leavevmode{[}list{]}
effective wavelength of each filter; this is set to None for the
filters Lbol, QH0, QHe0, and QHe1; omitted if nofilterdata is
True

\item[{filter\_wl}] \leavevmode{[}list of arrays{]}
a list giving the wavelength table for each filter; this is
None for the filters Lbol, QH0, QHe0, and QHe1; omitted if
nofilterdata is True

\item[{filter\_response}] \leavevmode{[}list of arrays{]}
a list giving the photon response function for each filter;
this is None for the filters Lbol, QH0, QHe0, and QHe1; omitted
if nofilterdata is True

\item[{filter\_beta}] \leavevmode{[}list{]}
powerlaw index beta for each filter; used to normalize the
photometry

\item[{filter\_wl\_c}] \leavevmode{[}list{]}
pivot wavelength for each filter; used to normalize the photometry

\item[{phot}] \leavevmode{[}array, shape (N\_cluster, N\_filter){]}
photometric value in each filter for each cluster; units are as
indicated in the units field

\end{description}

\item[{Raises}] \leavevmode
IOError, if no photometry file can be opened
ValueError, if photsystem is set to an unknown values

\end{description}

\end{fulllineitems}

\index{read\_cluster\_prop() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.read_cluster_prop}\pysiglinewithargsret{\code{slugpy.}\bfcode{read\_cluster\_prop}}{\emph{model\_name}, \emph{output\_dir=None}, \emph{fmt=None}, \emph{verbose=False}, \emph{read\_info=None}}{}
Function to read a SLUG2 cluster\_prop file.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{model\_name}] \leavevmode{[}string{]}
The name of the model to be read

\item[{output\_dir}] \leavevmode{[}string{]}
The directory where the output is located; if set to None,
the current directory is searched, followed by the SLUG\_DIR
directory if that environment variable is set

\item[{fmt}] \leavevmode{[}string{]}
Format for the file to be read. Allowed values are `ascii',
`bin' or `binary, and `fits'. If one of these is set, the code
will only attempt to open ASCII-, binary-, or FITS-formatted
output, ending in .txt., .bin, or .fits, respectively. If set
to None, the code will try to open ASCII files first, then if
it fails try binary files, and if it fails again try FITS
files.

\item[{verbose}] \leavevmode{[}bool{]}
If True, verbose output is printed as code runs

\item[{read\_info}] \leavevmode{[}dict{]}
On return, this dict will contain the keys `fname' and
`format', giving the name of the file read and the format it
was in; `format' will be one of `ascii', `binary', or `fits'

\end{description}

\item[{Returns}] \leavevmode
A namedtuple containing the following fields:
\begin{description}
\item[{id}] \leavevmode{[}array, dtype uint{]}
unique ID of cluster

\item[{trial: array, dtype uint}] \leavevmode
which trial was this cluster part of

\item[{time}] \leavevmode{[}array{]}
time at which cluster's properties are being evaluated

\item[{form\_time}] \leavevmode{[}array{]}
time when cluster formed

\item[{lifetime}] \leavevmode{[}array{]}
time at which cluster will disrupt

\item[{target\_mass}] \leavevmode{[}array{]}
target cluster mass

\item[{actual\_mass}] \leavevmode{[}array{]}
actual mass at formation

\item[{live\_mass}] \leavevmode{[}array{]}
mass of currently living stars

\item[{num\_star}] \leavevmode{[}array, dtype ulonglong{]}
number of living stars in cluster being treated stochastically

\item[{max\_star\_mass}] \leavevmode{[}array{]}
mass of most massive living star in cluster

\end{description}

\end{description}

\end{fulllineitems}

\index{read\_cluster\_spec() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.read_cluster_spec}\pysiglinewithargsret{\code{slugpy.}\bfcode{read\_cluster\_spec}}{\emph{model\_name}, \emph{output\_dir=None}, \emph{fmt=None}, \emph{verbose=False}, \emph{read\_info=None}}{}
Function to read a SLUG2 cluster\_spec file.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{model\_name}] \leavevmode{[}string{]}
The name of the model to be read

\item[{output\_dir}] \leavevmode{[}string{]}
The directory where the SLUG2 output is located; if set to None,
the current directory is searched, followed by the SLUG\_DIR
directory if that environment variable is set

\item[{fmt}] \leavevmode{[}string{]}
Format for the file to be read. Allowed values are `ascii',
`bin' or `binary, and `fits'. If one of these is set, the code
will only attempt to open ASCII-, binary-, or FITS-formatted
output, ending in .txt., .bin, or .fits, respectively. If set
to None, the code will try to open ASCII files first, then if
it fails try binary files, and if it fails again try FITS
files.

\item[{verbose}] \leavevmode{[}bool{]}
If True, verbose output is printed as code runs

\item[{read\_info}] \leavevmode{[}dict{]}
On return, this dict will contain the keys `fname' and
`format', giving the name of the file read and the format it
was in; `format' will be one of `ascii', `binary', or `fits'

\end{description}

\item[{Returns}] \leavevmode
A namedtuple containing the following fields:
\begin{description}
\item[{id}] \leavevmode{[}array, dtype uint{]}
unique ID of cluster

\item[{trial: array, dtype uint}] \leavevmode
which trial was this cluster part of

\item[{time}] \leavevmode{[}array{]}
times at which cluster spectra are output, in yr

\item[{wl}] \leavevmode{[}array{]}
wavelength, in Angstrom

\item[{spec}] \leavevmode{[}array, shape (N\_cluster, N\_wavelength){]}
specific luminosity of each cluster at each wavelength, in erg/s/A

\end{description}

\item[{Raises}] \leavevmode
IOError, if no spectrum file can be opened

\end{description}

\end{fulllineitems}

\index{read\_filter() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.read_filter}\pysiglinewithargsret{\code{slugpy.}\bfcode{read\_filter}}{\emph{filtername}, \emph{filter\_dir=None}}{}
Function to read a filter or set of filters for SLUG2. By default
this function searches the SLUG\_DIR/lib/filter directory, followed
by the current working directory. This can be overridden by the
filter\_dir keyword.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{filtername}] \leavevmode{[}string or iterable containing strings{]}
Name or names of filters to be read; for the special filters
Lbol, QH0, QHe0, and QHe1, the return value will be None

\item[{filter\_dir}] \leavevmode{[}string{]}
Directory where the filter data files can be found

\end{description}

\item[{Returns}] \leavevmode
A namedtuple containing the following fields:
\begin{description}
\item[{wl\_eff}] \leavevmode{[}float or array{]}
Central wavelength of the filter, defined by 
wl\_eff = exp(int R ln lambda dln lambda / int R dln lambda)

\item[{wl}] \leavevmode{[}array or list of arrays{]}
Wavelength table for each filter, in Ang

\item[{response}] \leavevmode{[}array or list of arrays{]}
Response function per photon for each filter

\item[{beta}] \leavevmode{[}float or array{]}
Index beta for the filter

\item[{wl\_c}] \leavevmode{[}float or array{]}
Pivot wavelength for the filter; used when beta != 0 to
normalize the photometry

\end{description}

\item[{Raises}] \leavevmode
IOError, if the filter data files cannot be opened, or if the
requested filter cannot be found

\end{description}

\end{fulllineitems}

\index{read\_integrated() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.read_integrated}\pysiglinewithargsret{\code{slugpy.}\bfcode{read\_integrated}}{\emph{model\_name}, \emph{output\_dir=None}, \emph{fmt=None}, \emph{nofilterdata=False}, \emph{photsystem=None}, \emph{verbose=False}, \emph{read\_info=None}}{}
Function to read all integrated light data for a SLUG2 run.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{model\_name}] \leavevmode{[}string{]}
The name of the model to be read

\item[{output\_dir}] \leavevmode{[}string{]}
The directory where the SLUG2 output is located; if set to None,
the current directory is searched, followed by the SLUG\_DIR
directory if that environment variable is set

\item[{fmt}] \leavevmode{[}string{]}
Format for the file to be read. Allowed values are `ascii',
`bin' or `binary, and `fits'. If one of these is set, the code
will only attempt to open ASCII-, binary-, or FITS-formatted
output, ending in .txt., .bin, or .fits, respectively. If set
to None, the code will try to open ASCII files first, then if
it fails try binary files, and if it fails again try FITS
files.

\item[{nofilterdata}] \leavevmode{[}bool{]}
If True, the routine does not attempt to read the filter
response data from the standard location

\item[{photsystem}] \leavevmode{[}None or string{]}
If photsystem is None, the data will be returned in the same
photometric system in which they were read. Alternately, if it
is a string, the data will be converted to the specified
photometric system. Allowable values are `L\_nu', `L\_lambda',
`AB', `STMAG', and `Vega', corresponding to the options defined
in the SLUG code. If this is set and the conversion requested
involves a conversion from a wavelength-based system to a
frequency-based one, nofilterdata must be False so that the
central wavelength of the photometric filters is available.

\item[{verbose}] \leavevmode{[}bool{]}
If True, verbose output is printed as code runs

\item[{read\_info}] \leavevmode{[}dict{]}
On return, this dict will contain the keys `prop\_name',
`phot\_name', `spec\_name', `cloudyspec\_name', `cloudylines\_name'
and `format', giving the names of the files read and the format
they were in; `format' will be one of `ascii', `binary', or
`fits'. If one of the files is not present, the corresponding
\_name key will be omitted from the dict.

\end{description}

\item[{Returns}] \leavevmode
A namedtuple containing the following fields:

(Always present)
\begin{description}
\item[{time: array}] \leavevmode
Times at which data are output

\end{description}

(Only present if an integrated\_prop file is found)
\begin{description}
\item[{target\_mass}] \leavevmode{[}array, shape (N\_times){]}
Target stellar mass at each time

\item[{actual\_mass}] \leavevmode{[}array, shape (N\_times, N\_trials){]}
Actual mass of stars created up to each time in each trial

\item[{live\_mass}] \leavevmode{[}array, shape (N\_times, N\_trials){]}
Mass of currently-alive stars at each time in each trial

\item[{cluster\_mass}] \leavevmode{[}array, shape (N\_times, N\_trials){]}
Mass of living stars in non-disrupted clusters at each time in
each trial

\item[{num\_clusters}] \leavevmode{[}array, shape (N\_times, N\_trials), dtype ulonglong{]}
Number of non-disrupted clusters present at each time in each
trial

\item[{num\_dis\_clusters}] \leavevmode{[}array, shape (N\_times, N\_trials), dtype ulonglong{]}
Number of disrupted clusters present at each time in each trial

\item[{num\_fld\_stars}] \leavevmode{[}array, shape (N\_times, N\_trials), dtype ulonglong{]}
Number of living field stars (excluding those in disrupted 
clusters and those being treated non-stochastically) present at
each time in each trial

\end{description}

(Only present if an integrated\_spec file is found)
\begin{description}
\item[{wl}] \leavevmode{[}array{]}
wavelengths, in Angstrom

\item[{spec}] \leavevmode{[}array, shape (N\_wavelength, N\_times, N\_trials){]}
specific luminosity at each wavelength and each time for each
trial, in erg/s/A

\end{description}

(Only present if an integrated\_phot file is found)
\begin{description}
\item[{filter\_names}] \leavevmode{[}list of string{]}
a list giving the name for each filter

\item[{filter\_units}] \leavevmode{[}list of string{]}
a list giving the units for each filter

\item[{filter\_wl\_cen}] \leavevmode{[}list{]}
central wavelength of each filter; this is set to None for the
filters Lbol, QH0, QHe0, and QHe1; omitted if nofilterdata is
True

\item[{filter\_wl}] \leavevmode{[}list of arrays{]}
a list giving the wavelength table for each filter; this is
None for the filters Lbol, QH0, QHe0, and QHe1; omitted if
nofilterdata is True

\item[{filter\_response}] \leavevmode{[}list of arrays{]}
a list giving the photon response function for each filter;
this is None for the filters Lbol, QH0, QHe0, and QHe1; omitted
if nofilterdata is True

\item[{phot}] \leavevmode{[}array, shape (N\_filter, N\_times, N\_trials){]}
photometric value in each filter at each time in each trial;
units are as indicated in the units field

\end{description}

\end{description}

\end{fulllineitems}

\index{read\_integrated\_phot() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.read_integrated_phot}\pysiglinewithargsret{\code{slugpy.}\bfcode{read\_integrated\_phot}}{\emph{model\_name}, \emph{output\_dir=None}, \emph{fmt=None}, \emph{nofilterdata=False}, \emph{photsystem=None}, \emph{verbose=False}, \emph{read\_info=None}}{}
Function to read a SLUG2 integrated\_phot file.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{model\_name}] \leavevmode{[}string{]}
The name of the model to be read

\item[{output\_dir}] \leavevmode{[}string{]}
The directory where the SLUG2 output is located; if set to None,
the current directory is searched, followed by the SLUG\_DIR
directory if that environment variable is set

\item[{fmt}] \leavevmode{[}string{]}
Format for the file to be read. Allowed values are `ascii',
`bin' or `binary, and `fits'. If one of these is set, the code
will only attempt to open ASCII-, binary-, or FITS-formatted
output, ending in .txt., .bin, or .fits, respectively. If set
to None, the code will try to open ASCII files first, then if
it fails try binary files, and if it fails again try FITS
files.

\item[{nofilterdata}] \leavevmode{[}bool{]}
If True, the routine does not attempt to read the filter
response data from the standard location

\item[{photsystem}] \leavevmode{[}None or string{]}
If photsystem is None, the data will be returned in the same
photometric system in which they were read. Alternately, if it
is a string, the data will be converted to the specified
photometric system. Allowable values are `L\_nu', `L\_lambda',
`AB', `STMAG', and `Vega', corresponding to the options defined
in the SLUG code. If this is set and the conversion requested
involves a conversion from a wavelength-based system to a
frequency-based one, nofilterdata must be False so that the
central wavelength of the photometric filters is available.

\item[{verbose}] \leavevmode{[}bool{]}
If True, verbose output is printed as code runs

\item[{read\_info}] \leavevmode{[}dict{]}
On return, this dict will contain the keys `fname' and
`format', giving the name of the file read and the format it
was in; `format' will be one of `ascii', `binary', or `fits'

\end{description}

\item[{Returns}] \leavevmode
A namedtuple containing the following fields:
\begin{description}
\item[{time}] \leavevmode{[}array{]}
times at which colors are output, in yr

\item[{filter\_names}] \leavevmode{[}list of string{]}
a list giving the name for each filter

\item[{filter\_units}] \leavevmode{[}list of string{]}
a list giving the units for each filter

\item[{filter\_wl\_eff}] \leavevmode{[}list{]}
effective wavelength of each filter; this is set to None for the
filters Lbol, QH0, QHe0, and QHe1; omitted if nofilterdata is
True

\item[{filter\_wl}] \leavevmode{[}list of arrays{]}
a list giving the wavelength table for each filter; this is
None for the filters Lbol, QH0, QHe0, and QHe1; omitted if
nofilterdata is True

\item[{filter\_response}] \leavevmode{[}list of arrays{]}
a list giving the photon response function for each filter;
this is None for the filters Lbol, QH0, QHe0, and QHe1; omitted
if nofilterdata is True

\item[{filter\_beta}] \leavevmode{[}list{]}
powerlaw index beta for each filter; used to normalize the
photometry

\item[{filter\_wl\_c}] \leavevmode{[}list{]}
pivot wavelength for each filter; used to normalize the photometry

\item[{phot}] \leavevmode{[}array, shape (N\_filter, N\_times, N\_trials){]}
photometric value in each filter at each time in each trial;
units are as indicated in the units field

\end{description}

\item[{Raises}] \leavevmode
IOError, if no photometry file can be opened
ValueError, if photsystem is set to an unknown value

\end{description}

\end{fulllineitems}

\index{read\_integrated\_prop() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.read_integrated_prop}\pysiglinewithargsret{\code{slugpy.}\bfcode{read\_integrated\_prop}}{\emph{model\_name}, \emph{output\_dir=None}, \emph{fmt=None}, \emph{verbose=False}, \emph{read\_info=None}}{}
Function to read a SLUG2 integrated\_prop file.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{model\_name}] \leavevmode{[}string{]}
The name of the model to be read

\item[{output\_dir}] \leavevmode{[}string{]}
The directory where the SLUG2 output is located; if set to None,
the current directory is searched, followed by the SLUG\_DIR
directory if that environment variable is set

\item[{fmt}] \leavevmode{[}string{]}
Format for the file to be read. Allowed values are `ascii',
`bin' or `binary, and `fits'. If one of these is set, the code
will only attempt to open ASCII-, binary-, or FITS-formatted
output, ending in .txt., .bin, or .fits, respectively. If set
to None, the code will try to open ASCII files first, then if
it fails try binary files, and if it fails again try FITS
files.

\item[{verbose}] \leavevmode{[}bool{]}
If True, verbose output is printed as code runs

\item[{read\_info}] \leavevmode{[}dict{]}
On return, this dict will contain the keys `fname' and
`format', giving the name of the file read and the format it
was in; `format' will be one of `ascii', `binary', or `fits'

\end{description}

\item[{Returns}] \leavevmode
A namedtuple containing the following fields:
\begin{description}
\item[{time}] \leavevmode{[}array{]}
Times at which data are output

\item[{target\_mass}] \leavevmode{[}array, shape{]}
Target stellar mass at each time

\item[{actual\_mass}] \leavevmode{[}array, shape (N\_times, N\_trials){]}
Actual mass of stars created up to each time in each trial

\item[{live\_mass}] \leavevmode{[}array, shape (N\_times, N\_trials){]}
Mass of currently-alive stars at each time in each trial

\item[{cluster\_mass}] \leavevmode{[}array, shape (N\_times, N\_trials){]}
Mass of living stars in non-disrupted clusters at each time in
each trial

\item[{num\_clusters}] \leavevmode{[}array, shape (N\_times, N\_trials), dtype ulonglong{]}
Number of non-disrupted clusters present at each time in each
trial

\item[{num\_dis\_clusters}] \leavevmode{[}array, shape (N\_times, N\_trials), dtype ulonglong{]}
Number of disrupted clusters present at each time in each trial

\item[{num\_fld\_stars}] \leavevmode{[}array, shape (N\_times, N\_trials), dtype ulonglong{]}
Number of living field stars (excluding those in disrupted 
clusters and those being treated non-stochastically) present at
each time in each trial

\end{description}

\end{description}

\end{fulllineitems}

\index{read\_integrated\_spec() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.read_integrated_spec}\pysiglinewithargsret{\code{slugpy.}\bfcode{read\_integrated\_spec}}{\emph{model\_name}, \emph{output\_dir=None}, \emph{fmt=None}, \emph{verbose=False}, \emph{read\_info=None}}{}
Function to read a SLUG2 integrated\_spec file.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{model\_name}] \leavevmode{[}string{]}
The name of the model to be read

\item[{output\_dir}] \leavevmode{[}string{]}
The directory where the SLUG2 output is located; if set to None,
the current directory is searched, followed by the SLUG\_DIR
directory if that environment variable is set

\item[{fmt}] \leavevmode{[}string{]}
Format for the file to be read. Allowed values are `ascii',
`bin' or `binary, and `fits'. If one of these is set, the code
will only attempt to open ASCII-, binary-, or FITS-formatted
output, ending in .txt., .bin, or .fits, respectively. If set
to None, the code will try to open ASCII files first, then if
it fails try binary files, and if it fails again try FITS
files.

\item[{verbose}] \leavevmode{[}bool{]}
If True, verbose output is printed as code runs

\item[{read\_info}] \leavevmode{[}dict{]}
On return, this dict will contain the keys `fname' and
`format', giving the name of the file read and the format it
was in; `format' will be one of `ascii', `binary', or `fits'

\end{description}

\item[{Returns}] \leavevmode
A namedtuple containing the following fields:
\begin{description}
\item[{time}] \leavevmode{[}array{]}
times at which spectra are output, in yr

\item[{wl}] \leavevmode{[}array{]}
wavelength, in Angstrom

\item[{spec}] \leavevmode{[}array, shape (N\_wavelength, N\_times, N\_trials){]}
specific luminosity at each wavelength and each time for each
trial, in erg/s/A

\end{description}

\end{description}

\end{fulllineitems}

\index{read\_summary() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.read_summary}\pysiglinewithargsret{\code{slugpy.}\bfcode{read\_summary}}{\emph{model\_name}, \emph{output\_dir=None}}{}
Function to open a SLUG output summary file.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{model\_name}] \leavevmode{[}string{]}
The name of the model to be read

\item[{output\_dir}] \leavevmode{[}string{]}
The directory where the SLUG2 output is located; if set to None,
the current directory is searched, followed by the SLUG\_DIR
directory if that environment variable is set

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{summary}] \leavevmode{[}dict{]}
A dict containing all the keywords stored in the output file

\end{description}

\item[{Raises}] \leavevmode
IOError, if a summary file for the specified model cannot be found

\end{description}

\end{fulllineitems}

\index{slug\_open() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.slug_open}\pysiglinewithargsret{\code{slugpy.}\bfcode{slug\_open}}{\emph{filename}, \emph{output\_dir=None}, \emph{fmt=None}}{}
Function to open a SLUG2 output file.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{filename}] \leavevmode{[}string{]}
Name of the file to open, without any extension. The following
extensions are tried, in order: .txt, .bin, .fits

\item[{output\_dir}] \leavevmode{[}string{]}
The directory where the SLUG2 output is located; if set to None,
the current directory is searched, followed by the
SLUG\_DIR/output directory if the SLUG\_DIR environment variable
is set

\item[{fmt}] \leavevmode{[}string{]}
Format for the file to be read. Allowed values are `ascii',
`bin' or `binary, and `fits'. If one of these is set, the code
will only attempt to open ASCII-, binary-, or FITS-formatted
output, ending in .txt., .bin, or .fits, respectively. If set
to None, the code will try to open ASCII files first, then if
it fails try binary files, and if it fails again try FITS
files.

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{fp}] \leavevmode{[}file or astropy.io.fits.hdu.hdulist.HDUList{]}
A file object pointing the file that has been opened

\item[{fname}] \leavevmode{[}string{]}
Name of the file that was opened

\end{description}

\item[{Raises}] \leavevmode
IOError, if a file of the specified name cannot be found

\end{description}

\end{fulllineitems}

\index{write\_cluster() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.write_cluster}\pysiglinewithargsret{\code{slugpy.}\bfcode{write\_cluster}}{\emph{data}, \emph{model\_name}, \emph{fmt}}{}
Function to write a set of output cluster files in SLUG2 format,
starting from a cluster data set as returned by read\_cluster.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{data}] \leavevmode{[}namedtuple{]}
Cluster data to be written, in the namedtuple format returned
by read\_cluster

\item[{model\_name}] \leavevmode{[}string{]}
Base file name to give the model to be written. Can include a
directory specification if desired.

\item[{fmt}] \leavevmode{[}string{]}
Format for the output file. Allowed values are `ascii', `bin'
or `binary, and `fits'.

\end{description}

\item[{Returns}] \leavevmode
Nothing

\end{description}

\end{fulllineitems}

\index{write\_integrated() (in module slugpy)}

\begin{fulllineitems}
\phantomsection\label{slugpy:slugpy.write_integrated}\pysiglinewithargsret{\code{slugpy.}\bfcode{write\_integrated}}{\emph{data}, \emph{model\_name}, \emph{fmt}}{}
Function to write a set of output integrated files in SLUG2 format,
starting from an integrated data set as returned by
read\_integrated.
\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{data}] \leavevmode{[}namedtuple{]}
Integrated data to be written, in the namedtuple format returned
by read\_integrated

\item[{model\_name}] \leavevmode{[}string{]}
Base file name to give the model to be written. Can include a
directory specification if desired.

\item[{fmt}] \leavevmode{[}string{]}
Format for the output file. Allowed values are `ascii', `bin'
or `binary, and `fits'.

\end{description}

\item[{Returns}] \leavevmode
Nothing

\end{description}

\end{fulllineitems}



\chapter{Test Problems}
\label{tests:test-problems}\label{tests::doc}\label{tests:sec-tests}
This section describes a set of problems that can be used to test and explore the different capabilities of SLUG. SLUG ships a set of problems \code{problemname} that are specified by a parameter file \code{param/problemname.param}. Problems that require multiple simulations are described instead by multiple paramater files, each with unique ID XX:  \code{param/problemnameXX.param}. Users can reproduce the output of the test problems with the provided executable scripts  \code{test/run\_problemname.sh}. For each problem, a script for analysis is distributed  in \code{test/problemname.py}. Details for each test problem are given below.  Throughout this section, it is assumed that the \code{SLUG\_DIR} has been properly set.


\section{Problem \texttt{example}: basic galaxy simulation}
\label{tests:problem-example-basic-galaxy-simulation}
This problem illustrates the basic usage of slugin \code{galaxy} mode by running 48 realizations of a galaxy with constant \(\mathrm{SFR}=0.001\; M_\odot\;\mathrm{yr}^{-1}\), up to a maximum time of \(2\times 10^8\) yr. By issuing the command \code{test/run\_example.sh} the output files \code{SLUG\_EXAMPLE*} are generated. Once the models are ready, \code{python test/plot\_example.py} produces a multi-panel figure \code{test/SLUG\_EXAMPLE\_f1.pdf}.

The top-left panel shows the actual mass produced by SLUG for each of the 48 models at different time steps as a function of the targeted mass. One can see that SLUG realizations only approximate the desired mass, which is a consequence
of SLUG core algorithm. The 1:1 relation is shown by a red dashed line.
The remaining panels show examples of integrated photometry (as labeled) of all simulated galaxies
at different time steps, as a function of the actual mass. Due to its stochastic nature, SLUG produces
distributions rather than single values for each time step. The expected rate of ionizing
photon and the bolometric luminosities for a deterministic model with a
continuous star formation rate of \(\mathrm{SFR}=0.001\; M_\odot\;\mathrm{yr}^{-1}\) are shown
by red dashed lines in the relevant panels.


\section{Problem \texttt{example\_cluster}: basic cluster simulation}
\label{tests:problem-example-cluster-basic-cluster-simulation}
This problem illustrates the basic usage of SLUG in \code{cluster} mode by running 1000 realizations of a cluster with mass 500 \(M_\odot\),
up to a maximum time of 10 Myr. By issuing the command
\code{test/run\_example\_cluster.sh} the output files \code{SLUG\_CLUSTER\_EXAMPLE*} are
generated. Once the models are ready, \code{python test/plot\_example\_cluster.py} produces a multi-panel figure \code{test/SLUG\_CLUSTER\_EXAMPLE\_f1.pdf}.

This figure is divided in two columns: the left one shows outputs at the first time step, 1 Myr, while the second one shows outputs at the last time step, 10 Myr.  The top row shows the actual cluster mass for an input mass of \(500\;M_\odot\).
In \code{cluster} mode, all clusters are generated at the first time step and they evolve
passively after that. Thus, the mass does not change. As a consequence of the
random drawing from the IMF, masses are distributed around the input mass.
As the wanted mass is large enough to allow for many stars to be drawn, the
actual mass distribution is narrow.

The second raw shows instead the distribution of the maximum mass of all stars that are still
alive at a given time step. At 1 Myr, this distribution is a good approximation of the
input distribution, which is the result of random draws from the IMF. At 10 Myr, which is the
typical lifetime of a 15-20 \(M_\odot\) star, the most massive stars have died, and
SLUG stops following them. The distribution of luminosities, and particularly those
most sensitive to the presence of massive stars, change accordingly
(third and fourth row for \(Q_{H_0}\) and FUV).


\section{Problem \texttt{constsampl}: importance of constrained sampling}
\label{tests:problem-constsampl-importance-of-constrained-sampling}
This problem illustrates in more details the effects of constrained sampling on SLUG simulations,
which is the first key ingredient in the core algorithm of SLUG.

{[}change cluster mass to show how max mass changes{]}


\section{Problem \texttt{sampling}: different sampling techniques}
\label{tests:problem-sampling-different-sampling-techniques}
This problem highlights the flexible choice of sampling techniques in SLUG, which is
a new capability of v2.

{[}basic run with different sampling{]}


\section{Problem \texttt{imfchoice}: different IMF implementations}
\label{tests:problem-imfchoice-different-imf-implementations}
This problem highlights the flexible choice of IMF implementations in SLUG.

{[}basic run with different imfs{]}


\section{Problem \texttt{cmfchoice}: different CMF implementations}
\label{tests:problem-cmfchoice-different-cmf-implementations}
This problem highlights the flexible choice of CMF implementations in SLUG.

{[}basic run with different cmfs{]}


\section{Problem \texttt{sfhsampling}: realizations of SFH}
\label{tests:problem-sfhsampling-realizations-of-sfh}
This problem illustrates the conceptual difference between an input SFH and the effective
realizations produced by SLUG, in comparison to deterministic codes.

{[}show how a input SFH gets implemented in different realizations{]}


\section{Problem \texttt{cldisrupt}: cluster disruption at work}
\label{tests:problem-cldisrupt-cluster-disruption-at-work}
This problem highlights the flexible choice of CLF implementations in SLUG.

{[}basic run with different clfs{]}


\section{Problem \texttt{clfraction}: cluster fraction at work}
\label{tests:problem-clfraction-cluster-fraction-at-work}
This problem highlights the flexible choice of cluster fraction during SLUG simulations.

{[}basic run with different fc{]}


\section{Problem \texttt{spectra}: full spectra}
\label{tests:problem-spectra-full-spectra}
This problem highlights the power of the new feature offered in SLUG v2: the ability to produce
full spectra.

{[}basic run with full spectra out: shows stochasticity applied to spectra{]}


\section{Problem \texttt{redshift}: trivial redshift example}
\label{tests:problem-redshift-trivial-redshift-example}
This problem shows a trivial example of the redshift capability in SLUG v2.

{[}basic run with full spectra out at a different redshift{]}


\chapter{Indices and tables}
\label{index:indices-and-tables}\begin{itemize}
\item {} 
\emph{genindex}

\item {} 
\emph{modindex}

\item {} 
\emph{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{s}
\item {\texttt{slugpy}}, \pageref{slugpy:module-slugpy}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
