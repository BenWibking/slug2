\documentclass[12pt]{article}

\usepackage{hyperref, multirow, tablefootnote}

\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.5in}
\setlength{\topmargin}{-0.5in}
\setlength{\parindent}{0.5in}

\newcommand{\slug}{\texttt{slug}}
\newcommand{\Slug}{\texttt{Slug}}
\newcommand{\slugpy}{\texttt{slugpy}}
\newcommand{\Slugpy}{\texttt{Slugpy}}

\begin{document}

\title{User's Guide for \slug\ v.~2.0}
\author{Mark Krumholz}

\maketitle

\tableofcontents

\clearpage

\section{License and Citations}

This is a guide for users of the \slug\ software package. \slug\ is distributed under the terms of the \href{http://www.gnu.org/licenses/gpl.html}{GNU General Public License v.~3}. A copy of the license notification is included in the main \slug\ directory. If you use \slug\ in any published work, please cite the \slug\ method paper, da Silva, R.~L., Fumagalli, M., \& Krumholz, M.~R., 2012, \textit{The Astrophysical Journal}, 745, 145. A second method paper, describing the upgraded version 2 code and a set of ancillary tools, is in preparation at this time.

\section{What Does \slug\ Do?}

\Slug\ is a stellar population synthesis (SPS) code, meaning that, for a specified stellar initial mass function (IMF), star formation history (SFH), cluster mass function (CMF), and cluster lifetime function (CLF), it predicts the spectra and photometry of both individual star clusters and the galaxies (or sub-regions of galaxies) that contain them. In this regard, \slug\ operates much like any other SPS code. The main difference is that \slug\ regards the IMF, SFH, CMF, and CLF as probability distributions, and the resulting stellar population as being the result of a draw from them. \slug\ performs a Monte Carlo simulation to determine the PDF of the light produced by the stellar populations that are drawn from these distributions. The remainder of this section briefly describes the major conceptual pieces of a \slug\ simulation. For a more detailed description, readers are referred to \href{http://adsabs.harvard.edu/abs/2012ApJ...745..145D}{da Silva, Fumagalli, \& Krumholz (2012)}.

\subsection{Cluster Simulations and Galaxy Simulations}

\Slug\ can simulate either a simple stellar population (i.e., a group of stars all born at one time) or a composite stellar population, consisting of stars born at a distribution of times. We refer to the former case as a ``cluster" simulation, and the latter as a ``galaxy" simulation, since one can be thought of as approximating the behavior of a single star cluster, and the other as approximating a whole galaxy.

\subsection{Probability Distribution Functions: the IMF, SFH, CMF, and CLF}
\label{ssec:slugpdfs}

As mentioned above, \slug\ regards the IMF, SFH, CMF, and CLF as probability distribution functions. These PDFs can be described by a very wide range of possible functional forms; see Section \ref{sec:pdfs} for details on the exact functional forms allowed, and on how they can be specified in the code. When \slug\ runs a cluster simulation, it draws stars from the specified IMF in an attempt to produce a cluster of a user-specified total mass. There are a number of possible methods for performing such mass-limited sampling, and \slug\ gives the user a wide menu of options; see Section \ref{sec:pdfs}. 

For a galaxy simulation, the procedure involves one extra step. In this case, \slug\ assumes that some fraction $f_c$ of the stars in the galaxy are born in star clusters, which, for the purposes of \slug\, means that they all share the same birth time. The remaining fraction $1-f_c$ of stars are field stars. When a galaxy simulation is run, \slug\ determines the total mass of stars $M_*$ that should have formed since the start of the simulation (or since the last output, if more than one output is requested) from the star formation history, and then draws field stars and star clusters in an attempt to produce masses $(1-f_c)M_*$ and $f_c M_*$. For the field stars, the stellar masses are drawn from the IMF, in a process completely analogous to the cluster case. For star clusters, the masses of the clusters are drawn from the CMF, and each cluster is then populated from the IMF as in the cluster case. For both the field stars and the star clusters, the time of their birth is drawn from the PDF describing the SFH.

Finally, star clusters can be disrupted independent of the fate of their parent stars. When each cluster is formed, it is assigned a lifetime drawn from the CLF. Once that time has passed, the cluster ceases to be entered in the lists of individual cluster spectra and photometry (see next section), although the individual stars continue to contribute to the integrated light of the galaxy.

\subsection{Spectra and Photometry}
\label{ssec:spec_phot}

Once \slug\ has drawn a population of stars, its final step is to compute the light they produce. \Slug\ does this in several steps. First, it computes the physical properties of all the stars present user-specified times using a set of stellar evolutionary tracks. Second, it uses these physical properties to compute the composite spectra produced by the stars, using a user-specified set of stellar atmosphere models. Formally, the quantity computed is the specific luminosity per unit wavelength $L_\lambda$. Third and finally, it computes photometry for the stellar population by integrating the computed spectra over a set of specified photometric filters. Depending on the options specified by the user and the filter under consideration, the photometric value output will be one of the following:
\begin{itemize}
\item The frequency-averaged luminosity across the filter, defined as
\begin{equation}
\langle L_\nu\rangle_R = \frac{\int L_\nu \, d\ln\nu}{\int R_\nu (\nu/\nu_c)^\beta \, d\ln\nu},
\end{equation}
where $L_\nu$ is the specific luminosity per unit frequency, $R_\nu$ is the filter response function per photon at frequency $\nu$, $\nu_c$ is the central wavelength of the filter, and $\beta$ is a constant that is defined by convention for each filter, and is either 0, 1, or 2; usually it is 0 for optical and UV filters.
\item The wavelength-averaged luminosity across the filter, defined as
\begin{equation}
\langle L_\lambda\rangle_R = \frac{\int L_\lambda \, d\ln\lambda}{\int R_\lambda (\lambda/\lambda_c)^{-\beta} \, d\ln\lambda},
\end{equation}
where $L_\lambda$ is the specific luminosity per unit wavelength, $R_\lambda$ is the filter response function per photon at wavelength $\lambda$, and $\lambda_c$ is the central wavelength of the filter.
\item The AB magnitude, defined by
\begin{equation}
M_{\rm AB} = -2.5 \log_{10} \left[\frac{\langle L_\nu\rangle_R}{4\pi\left(10\,\mathrm{pc}\right)^2}\right] - 48.6,
\end{equation}
where $\langle L_\nu\rangle_R$ is in units of erg s$^{-1}$ Hz$^{-1}$.
\item The ST magnitude, defined by
\begin{equation}
%MF: changed the following line
%M_{\rm ST} = -2.5 \log_{10} \left[\frac{\langle L_\nu\rangle_R}{4\pi\left(10\,\mathrm{pc}\right)^2}\right] - 21.1,
M_{\rm ST} = -2.5 \log_{10} \left[\frac{\langle L_\lambda\rangle_R}{4\pi\left(10\,\mathrm{pc}\right)^2}\right] - 21.1,
\end{equation}
where $\langle L_\lambda\rangle_R$ is in units of erg s$^{-1}$ \AA$^{-1}$.
\item The Vega magnitude, defined by
\begin{equation}
M_{\rm Vega} = M_{\rm AB} - M_{\rm AB}(\mbox{Vega}),
\end{equation}
where $M_{\rm AB}(\mbox{Vega})$ is the AB magnitude of Vega. The latter quantity is computed on the fly, using a stored Kurucz model spectrum for Vega. 
\item The photon flux above some threshold $\nu_0$, defined as
\begin{equation}
Q(\nu_0) = \int_{\nu_0}^\infty \frac{L_\nu}{h\nu} \, d\nu.
\end{equation}
\item The bolometric luminosity,
\begin{equation}
L_{\rm bol} = \int_0^\infty L_\nu \, d\nu.
\end{equation}
\end{itemize}

For a cluster simulation, this procedure is applied to the star cluster being simulated at a user-specified set of output times. For a galaxy simulation, the procedure is much the same, but it can be done both for all the stars in the galaxy taken as a whole, and individually for each star cluster that is still present (i.e., that has not been disrupted).

\subsection{Monte Carlo Simulation}

The steps described in the previous two simulations are those required for a single realization of the stellar population. However, the entire point of \slug\ is to repeat this procedure many times in order to build up the statistics of the population light output. Thus the entire procedure can be repeated as many times as the user desires, in order to build up statistics.

\section{Compiling and Installing \slug}

\subsection{Dependencies}

The core \slug\ program requires
\begin{itemize}
\item The \href{http://www.boost.org/}{boost C++ libraries}
\item The \href{http://www.gnu.org/software/gsl/}{GNU scientific library}
\item The \href{http://heasarc.gsfc.nasa.gov/fitsio/fitsio.html}{cfitsio library} (optional)
\end{itemize}
Compilation will be easiest if you install these libraries such that the header files are included in your \verb=CXX_INCLUDE_PATH= and the compiled object files are in your \verb=LD_LIBRARY_PATH=. Alternately, you man manually specify the locations of these files by editing the Makefiles -- see below. The cfitsio library is optional, and is only required if you want the ability to write FITS output. To compile without it, use the flag \verb!FITS=DISABLE_FITS! when calling \verb=make= (see below).

In addition to the core dependencies, \slugpy, the python helper library requires:
\begin{itemize}
\item \href{http://www.numpy.org/}{numpy}
\item \href{http://www.scipy.org/}{scipy}
\item \href{http://www.astropy.org/}{astropy} (optional)
\end{itemize}
As with cfitsio, astropy is only required if you want the ability to read and manipulate FITS output. 

\subsection{Compiling}

If you have boost, GSL, and (if you're using it) cfitsio included in your \verb=CXX_INCLUDE_PATH= and \verb=LD_LIBRARY_PATH= environment variables, and your system is running either MacOSX or Linux, you should be able to compile simply by doing
\begin{verbatim}
make
\end{verbatim}
from the main \verb=slug= directory. To compile in debug mode, do \verb=make debug= instead. To compile without cfitsio, then do
\begin{verbatim}
make FITS=DISABLE_FITS
\end{verbatim}

Alternately, you can manually specify the compiler flags to be used by creating a file named \verb=Make.mach.MACHINE_NAME= in the \verb=src= directory, and then doing
\begin{verbatim}
make MACHINE=MACHINE_NAME
\end{verbatim}
An example machine-specific file, \verb=src/Make.mach.ucsc-hyades= is included in the repository. You can also override or reset any compilation flag you want by editing the file \verb=src/Make.config.override=

Finally, note that \slug\ is written in C++11, and requires some C++11 features, so it may not work with older C++ compilers. The following compiler versions are known to work: gcc $\geq$ 4.7, clang/llvm $\geq$ 3.3, icc $\geq 14.0$. Earlier versions may work as well, but no guarantees.

\section{Running a \slug\ Simulation in Serial or Parallel}

Once \slug\ is compiled, running a simulation is extremely simple. The first step, which is not required but makes life a lot simpler, is to set the environment variable \verb=SLUG_DIR= to the directory where you have installed \slug. If you are using a \verb=bash=-like shell, the syntax for this is
\begin{verbatim}
export SLUG_DIR = /path/to/slug
\end{verbatim}
while for a \verb=csh=-like shell, it is
\begin{verbatim}
setenv SLUG_DIR /path/to/slug
\end{verbatim}
This is helpful because \slug\ needs a lot of input data, and if you don't set this variable, you will have to manually specify where to find it.

Next, to run on a single processor, just do
\begin{verbatim}
./bin/slug param/filename.param
\end{verbatim}
where \verb=filename.param= is the name of a parameter file, formatted as specified in Section \ref{sec:parameters}. The code will write a series of output files as described in Section \ref{sec:output}.

If you have more than one core at your disposal, you can also run \slug\ in parallel, using the command line
\begin{verbatim}
python ./bin/slug.py param/filename.param
\end{verbatim}
This called a python script that automatically divides up the Monte Carlo trials you have requested between the available processors, then consolidates the output so that it looks the same as if you had run a single-processor job. The python script allows fairly fine-grained control of the parallelism. It accepts the following command line arguments:
\begin{itemize}
\item \verb=-n NPROC, --nproc NPROC=: this parameter specifies the number of simultaneous \slug\ processes to run. It defaults to the number of cores present on the machine where the code is running
\item \verb=-b BATCHSIZE, --batchsize BATCHSIZE=: this specifies how to many trials to do per \slug\ process. It defaults to the total number of trials requested divided by the total number of processes, rounded up, so that only one \slug\ process is run per processor. \textit{Rationale:} The default behavior is optimal from the standpoint of minimizing the overhead associated with reading data from disk, etc. However, if you are doing a very large number of runs that are going to require hours, days, or weeks to complete, and you probably want the code to checkpoint along the way. In that case it is probably wise to set this to a value smaller than the default in order to force output to be dumped periodically.
\item \verb=-nc, --noconsolidate=: by default the \verb=slug.py= script will take all the outputs produced by the parallel runs and consolidate them into single output files, matching what would have been produced had the code been run in serial mode. If set, this flag suppresses that behavior, and instead leaves the output as a series of files whose root names match the model name given in the parameter file, plus the extension \verb=_pPPPPP_nNNNNN=, where the digits \verb=PPPPP= give the number of the processor that produces that file, and the digits \verb=NNNNN= give the run number on that processor. \textit{Rationale}: normally consolidation is convenient. However, if the output is very large, this may produce undesirably bulky files. Furthermore, if one is doing a very large number of simulations over an extended period, and the \verb=slug.py= script is going to be run multiple times (e.g.\ due to wall clock limits on a cluster), it may be preferable to leave the files unconsolidated until all runs have been completed.
\end{itemize}


\section{Parameter Specification}
\label{sec:parameters}

\subsection{File Format}

An example parameter file is included as \verb=param/example.param= in the source tree. Parameter files for \slug\ are generically formatted as a series of entries of the form
\begin{verbatim}
keyword    value
\end{verbatim}
Any line starting with \verb=#= is considered to be a comment and is ignored, and anything on a line after a \verb=#= is similarly treated as a comment and ignored. Some general rules on keywords are:
\begin{itemize}
\item Keywords may appear in any order.
\item Some keywords have default values, indicated in parenthesis in the list below. These keywords are optional and need not appear in the parameter file. All others are required. 
\item Keywords and values are case-insensitive. 
\item Unless explicitly stated otherwise, units for mass are always $M_\odot$, units for time are always yr.
\item Any time a file or directory is specified, if it is given as a relative rather than absolute path, it is assumed to be relative to the environment variable \verb=$SLUG_DIR=. If this environment variable is not set, it is assumed to be relative to the current working directory.
\end{itemize}

The keywords recognized by \slug\ can be categorized as described in the remainder of this section.

\subsection{Basic keywords}

These specify basic data for the run.
\begin{itemize}
\item \verb=model_name= (\verb=SLUG_DEF=): name of the model. This will become the base filename for the output files.
\item \verb=out_dir= (\verb=output=): name of the directory into which output should be written.
\item \verb=verbosity= (\verb=1=): level of verbosity when running, with 0 indicating no output, 1 indicating some output, and 2 indicating a great deal of output.
\end{itemize}

\subsection{Simulation control keywords}

These control the operation of the simulation.
\begin{itemize}
\item \verb=sim_type= (\verb=galaxy=): set to \verb=galaxy= to run a ``galaxy" simulation (a composite stellar population), or to \verb=cluster= to run a ``cluster" simulation (a simple stellar population)
\item \verb=n_trials= (\verb=1=): number of trials to run
%MF: changed the following line
%\item \verb=log_time= (\verb=0=): set to 0 for logarithmic time step, 1 for linear time steps
\item \verb=log_time= (\verb=0=): set to 1 for logarithmic time step, 0 for linear time steps
\item \verb=time_step=: size of the time step. If \verb=log_time= is set to 0, this is in yr. If \verb=log_time= is set to 1, this is in dex (i.e., a value of 0.2 indicates that every 5 time steps correspond to a factor of 10 increase in time).
\item \verb=start_time=: first output time. This may be omitted if \verb=log_time= is set to 0, in which case it defaults to a value equal to \verb=time_step=.
\item \verb=end_time=: last output time, in yr. Note that not all the tracks include entries going out to times $>1$ Gyr, and the results will become inaccurate if the final time is larger than the tracks allow.
\item \verb=sfr=: star formation rate. Only used if \verb=sim_type= is \verb=galaxy=; for \verb=cluster=, it will be ignored, and can be omitted. If, instead of specifying a numerical value for this parameter, you specify the string \verb=sfh=, the code will interpret this as a flag that a star formation history should be read from the file specified by the \verb=sfh= keyword.
\item \verb=sfh=: name of star formation history file. This file is a PDF file, formatted as described in Section \ref{sec:pdfs}. This is ignored, and can be omitted, if \verb=sim_type= is \verb=cluster=, or if \verb=sfr= is not set to \verb=sfh=.
\item \verb=cluster_mass=: mass of the star cluster for simulations with \verb=sim_type= set to \verb=cluster=. This can be omitted, and will be ignored, if \verb=sim_type= is \verb=galaxy=.
\item \verb=redshift= (\verb=0=): place the system at the specified redshift. The computed spectra and photometry will then be computed in the observed rather than the rest frame of the system.
\end{itemize}

\subsection{Output control keyword}

These control what quantities are computed and written to disk.
\begin{itemize}
\item \verb=out_cluster= (\verb=1=): write out the physical properties of star clusters? Set to 1 for yes, 0 for no.
\item \verb=out_cluster_phot= (\verb=1=): write out the photometry of star clusters? Set to 1 for yes, 0 for no.
\item \verb=out_cluster_spec= (\verb=1=): write out the spectra of star clusters? Set to 1 for yes, 0 for no.
\item \verb=out_integrated= (\verb=1=): write out the integrated physical properties of the whole galaxy? Set to 1 for yes, 0 for no. This keyword is ignored if \verb=sim_type= is \verb=cluster=.
\item \verb=out_integrated_phot= (\verb=1=): write out the integrated photometry of the entire galaxy? Set to 1 for yes, 0 for no. This keyword is ignored if \verb=sim_type= is \verb=cluster=.
\item \verb=out_integrated_spec= (\verb=1=): write out the integrated spectra of the entire galaxy? Set to 1 for yes, 0 for no. This keyword is ignored if \verb=sim_type= is \verb=cluster=.
\item \verb=output_mode= (\verb=ascii=): set to \verb=ascii=, \verb=binary=, or \verb=fits=. Selecting \verb=ascii= causes the output to be written in ASCII text, which is human-readable, but produces much larger files. Selecting \verb=binary= causes the output to be written in raw binary; see Section \ref{sec:output} for a description of the output format. Selecting \verb=fits= causes the output to be written FITS format. This will be somewhat larger than raw binary output, but the resulting files will be portable between machines, which the raw binary files are not guaranteed to be. All three output modes can be read by the python library, though with varying speed -- ASCII output is slowest, FITS is intermediate, and binary is fastest.
\end{itemize}

\subsection{Physical model keywords}
\label{ssec:phys_keywords}

These specify the physical models to be used for stellar evolution, atmospheres, the IMF, etc.
\begin{itemize}
\item \verb=imf= (\verb=lib/imf/chabrier.imf=): name of the IMF descriptor file; this is a PDF file, formatted as described in Section \ref{sec:pdfs}. Note that \slug\ ships with the following IMF files pre-defined (in the directory \verb=lib/imf=)
\begin{itemize}
\item \verb=chabrier.imf= (single-star IMF from Chabrier, 2005, in ``The Initial Mass Function 50 Years Later", eds.~E.~Corbelli, F.~Palla, \& H.~Zinnecker, Springer: Dordrecht, p.~41)
\item \verb=chabrier03.imf= (single-star IMF from Chabrier, 2003, PASP, 115, 763-795)
\item \verb=kroupa.imf= (IMF from Kroupa, 2002, Science, 295, 82-91)
\item \verb=kroupa_sb99.imf= (simplified version of the Kroupa, 2002 IMF used by default by \verb=starburst99=, \url{http://www.stsci.edu/science/starburst99/docs/default.htm})
\item \verb=salpeter.imf= (single-component power law IMF from Salpeter, 1955, ApJ, 121, 161)
\end{itemize}
\item \verb=cmf= (\verb=lib/cmf/slug_default.cmf=): name of the CMF descriptor file; this is a PDF file, formatted as described in Section \ref{sec:pdfs}. The default selection is a power law $dN/dM \propto M^{-2}$ from $M= 10^2 - 10^7$ $M_\odot$. This is ignored, and may be omitted, if \verb=sim_type= is set to \verb=cluster=.
\item \verb=clf= (\verb=lib/clf/slug_default.clf=): name of the CLF descriptor file; this is a PDF file, formatted as described in Section \ref{sec:pdfs}. The default gives a power law distribution of lifetimes $t$ with $dN/dt\propto t^{-1.9}$ from 1 Myr to 1 Gyr. Note that this corresponds to a cluster age distribution of slope $-0.9$. The \slug\ source also ships with an alternative CLF file, \verb=lib/clf/nodisrupt.clf=, which disables cluster disruption entirely (by setting the lifetime distribution to a $\delta$ function at $10^{300}$ yr).
\item \verb=tracks= (\verb=lib/tracks/Z0140v00.txt=): stellar evolution tracks to use. The following tracks ship with \slug\ (all in the directory \verb=lib/tracks=):
\begin{itemize}
\item \verb=ZXXXXvYY.txt=: Geneva (2013) tracks; metallicities are Solar (\verb=XXXX= = \verb=0140=) and $1/7$ Solar (\verb=XXXX= = \verb=0020=), and rotation rates are 0 (\verb=YY= = \verb=00=) and 40\% of breakup (\verb=YY= = \verb=40=).
\item \verb=modcXXX.dat=: Geneva tracks with standard mass loss, for metallicities of $2\times$ Solar (\verb=040=), Solar (\verb=020=), $0.4\times$ Solar (\verb=008=), $0.2\times$ Solar (\verb=004=), and $0.05\times$ Solar (\verb=001=).
\item \verb=modeXXX.dat=: same as \verb=modcXXX.dat=, but with higher mass loss rates.
\item \verb=modpXXX.dat=: Padova tracks with thermally pulsing AGB stars; metallicities use the same scale as \verb=modcXXX.dat= files (i.e., \verb=020= is Solar).
\item \verb=modsXXX.dat=: same as \verb=modpXXX.dat=, but without thermally pulsing AGB stars
\end{itemize}
\item \verb=atmospheres= (\verb=lib/atmospheres=): directory where the stellar atmosphere library is located. Note that file names are hard-coded, so if you want to use different atmosphere models with a different format, you will have to write new source code to do so.
\item \verb=specsyn_mode= (\verb=sb99=): spectral synthesis mode. Allowed values are:
\begin{itemize}
\item \verb=planck=: treat all stars as black bodies
\item \verb=Kurucz=: use Kurucz atmospheres, as compiled by Lejeune et al.~(1997, A\&AS, 125, 229), for all stars
\item \verb=Kurucz+Hillier=: use Kurucz atmospheres for all stars except Wolf-Rayet stars; WR stars use Hillier model atmospheres (Hiller \& Miller, 1998, ApJ, 496, 407)
\item \verb=Kurucz+Pauldrach=: use Kurucz atmospheres for all stars except OB stars; OB stars use Pauldrach model atmospheres (Pauldrach et al., 2001, A\&A, 375, 161)
\item \verb=SB99=: emulate the behavior of \verb=starburst99=: use Pauldrach for OB stars, Hillier for WR stars, and Kurucz for all other stars
\end{itemize}
\item \verb=clust_frac= (\verb=1.0=): fraction of stars formed in clusters
\item \verb=min_stoch_mass= (\verb=0.0=): minimum stellar mass to be treated stochastically. All stars with masses below this value are assumed to be sampled continuously from the IMF.
\item \verb=metallicity=: metallicity of the stellar population, relative to solar. This may be omitted if \verb=tracks= is set to one of the default sets of tracks that ships with \slug, as the metallicities for these tracks are hardwired in. This keyword is provided to allow users to supply their own tracks.
\item \verb=WR_mass=: minimum starting mass that stars must have in order to pass through a Wolf-Rayet phase. This can be omitted if \verb=tracks= is set to one of the default sets of tracks that ships with \slug, as the WR cutoff masses for these tracks are hardwired in. This keyword is provided to allow users to supply their own tracks.
\end{itemize}

\subsection{Photometric filter keywords}
\label{ssec:phot_keywords}

These describe the photometry to be computed. Note that none of these keywords have any effect unless \verb=out_integrated_phot= or \verb=out_cluster_phot= is set to 1.
\begin{itemize}
\item \verb=phot_bands=: photometric bands for which photometry is to be computed. The values listed here can be comma- or whitespace-separated. For a list of available photometric filters, see the file \verb=lib/filters/FILTER_LIST=. In addition to these filters, \slug\ always allows four special ``bands":
\begin{itemize}
\item \verb=QH0=: the H$^0$ ionizing luminosity, in photons sec$^{-1}$
\item \verb=QHe0=: the He$^0$ ionizing luminosity, in photons sec$^{-1}$
\item \verb=QHe1=: the He$^+$ ionizing luminosity, in photons sec$^{-1}$
\item \verb=Lbol=: the bolometric luminosity, in $L_\odot$
\end{itemize}
\item \verb=filters= (\verb=lib/filters=): directory containing photometric filter data
\item \verb=phot_mode= (\verb=L_nu=): photometric system to be used when writing photometric outputs. Allowed values are:
\begin{itemize}
\item \verb=L_nu=: report frequency-averaged luminosity in the band, in units of erg/s/Hz
\item \verb=L_lambda=: report wavelength-averaged luminosity in the band, in units of erg/s/\AA
\item \verb=AB=: report AB magnitude
\item \verb=STMAG=: report ST magnitude
\item \verb=VEGA=: report Vega magnitude
\end{itemize}
Full definitions of the quantities computed for each of these choices are given in Section \ref{ssec:spec_phot}. Note that these values are ignored for the four special bands \verb=QH0=, \verb=QHe0=, \verb=QHe1=, and \verb=Lbol=. These four bands are always written out in the units specified above.
\end{itemize}

\section{Probability Distribution Functions}
\label{sec:pdfs}

The \slug\ code regards the IMF, the CMF, the CLF, and the SFH as probability distribution functions -- see Section \ref{ssec:slugpdfs}. The code provides a generic file format through which PDFs can be specified. Examples can be found in the \verb=lib/imf=, \verb=lib/cmf=, \verb=lib/clf=, and \verb=lib/sfh= directories of the \slug\ distribution.

PDFs in \slug\ are generically written as functions
\begin{equation}
\frac{dp}{dx} = n_1 f_1(x; x_{1,a}, x_{1,b}) + n_2 f_2(x; x_{2,a}, x_{2,b}) + n_3 f_3(x; x_{3,a}, x_{3,b}) + \cdots,
\end{equation}
where $f_i(x; x_{i,a}, x_{i,b})$ is non-zero only for $x \in [x_{i,a}, x_{i,b}]$. The functions $f_i$ are simple continuous functional forms, which we refer to as \textit{segments}. Functions in this form can be specified in \slug\ in two ways.


\subsection{Basic Mode}

The most common way of specifying a PDF is in basic mode. Basic mode describes a PDF that has the properties that (1) the segments are contiguous with one another, i.e., $x_{i,b} = x_{i+1,a}$, (2) $n_i f_i(x_{i,b}; x_{i,a}, x_{i,b}) = n_{i+1} f_{i+1}(x_{i+1,a}; x_{i+1,a}, x_{i+1,b})$, and (3) the overall PDF is normalized such that $\int (dp/dx)\, dx = 1$.\footnote{Note that SFH PDFs cannot be described using basic mode, because they are not normalized to unity. Specifying a non-constant SFH requires advanced mode.} Given these constraints, the PDF can be specified fully simply by giving the $x$ values that define the edges of the segments and the functional forms $f$ of each segment; the normalizations can be computed from the constraint equations.

An example of a basic mode PDF file is as follows:
\begin{verbatim}
###############################################################
# This is an IMF definition file for SLUG v2.
# This file defines the Chabrier (2005) IMF          
###############################################################

# Breakpoints: mass values where the functional form changes
# The first and last breakpoint will define the minimum and
# maximum mass
breakpoints 0.08 1 120

# Definitions of segments between the breakpoints

# This segment is a lognormal with a mean of log_10 (0.2 Msun) 
# and dispersion 0.55; the dispersion is in log base 10, not 
# log base e
segment
type lognormal
mean 0.2
disp 0.55

# This segment is a powerlaw of slope -2.35
segment
type powerlaw
slope -2.35
\end{verbatim}
This example represents a Chabrier (2005) IMF from $0.08 - 120$ $M_\odot$, which is of the functional form
\begin{equation}
\frac{dp}{dm} \propto \left\{
\begin{array}{ll}
\exp[-\log(m/m_0)^2/(2\sigma^2)] (m/m_b)^{-1} , & m < m_b \\
\exp[-\log(m_b/m_0)^2/(2\sigma^2)] (m/m_b)^{-2.35}, & m \geq m_b
\end{array}
\right.,
\end{equation}
where $m_0 = 0.2$ $M_\odot$, $\sigma = 0.55$, and $m_b = 1$ $M_\odot$.

Formally, the format of a basic mode file is as follows. Any line beginning with \verb=#= is a comment and is ignored. The first non-empty, non-comment line in a basic mode PDF file must be of the form
\begin{verbatim}
breakpoints x1 x2 x3 ...
\end{verbatim}
where \verb=x1=, \verb=x2=, \verb=x3=, \verb=...= are a non-decreasing series of real numbers. These represent the breakpoints that define the edges of the segment, in units of $M_\odot$. In the example given above, the breakpoints are are $0.08$, $1$, and $120$, indicating that the first segment goes from $0.08 - 1$ $M_\odot$, and the second from $1 - 120$ $M_\odot$.

After the \verb=breakpoints= line, there must be a series of entries of the form
\begin{verbatim}
segment
type TYPE
key1 VAL1
key2 VAL2
...
\end{verbatim}
where \verb=TYPE= specifies what functional form describes the segment, and \verb=key1 VAL1=, \verb=key2 VAL2=, etc.\ are a series of (key, value) pairs the define the free parameters for that segment. In the example above, the first segment is described as having a \verb=lognormal= functional form, and the keywords \verb=mean= and \verb=disp= specify that the lognormal has a mean of 0.2 $M_\odot$ and a dispersion of 0.55 in $\log_{10}$. The second segment is of type \verb=powerlaw=, and it has a slope of $-2.35$. The full list of allowed segment types and the keywords that must be specified with them are listed in Table \ref{tab:segtypes}. Keywords and segment types are case-insensitive. Where more than one keyword is required, the order is arbitrary.

\begin{table}
\scriptsize
\begin{center}
\begin{tabular}{lccccc}
\hline\hline
Name & Functional form & Keyword & Meaning & Keyword & Meaning \\
\hline
\verb=delta= & $\delta(x-x_a)$\tablefootnote{A \texttt{delta} PDF must be defined by a segment where $x_a = x_b$. It is an error if $x_a \neq x_b$.} & & & & \\
\verb=exponential= & $\exp(-x/x_*)$ & \verb=scale= & Scale length, $x_*$ & & \\
\verb=lognormal= & $x^{-1} \exp[-\log_{10}(x/x_0)^2/2\sigma^2]$ & \verb=mean= & Mean, $x_0$ & \verb=disp= & Dispersion in $\log_{10}$, $\sigma$ \\
\verb=normal= & $\exp[-(x-x_0)^2/2\sigma^2]$ & \verb=mean= & Mean, $x_0$ & \verb=disp= & Dispersion, $\sigma$ \\
\verb=powerlaw= & $x^p$ & \verb=slope= & Slope, $p$ & & \\
\verb=schechter= & $x^p \exp(-x/x_*)$ & \verb=slope= & Slope, $p$ & \verb=xstar= & Cutoff, $x_*$ \\ \hline
\end{tabular}
\caption{\label{tab:segtypes}
Types of PDF segments and corresponding keywords.
}
\end{center}
\end{table}

The total number of segments must be equal to one less than the number of breakpoints, so that each segment is described. Note that it is not necessary to specify a normalization for each segment, as the segments will be normalized relative to one another automatically so as to guarantee that the overall function is continuous.

\subsection{Advanced Mode}

In advanced mode, one has complete freedom to set all the parameters describing the PDF: the endpoints of each segment $x_{i,a}$ and $x_{i,b}$, the normalization of each segment $n_i$, and the functional forms of each segment $f_i$. This can be used to defined PDFs that are non-continuous, or that are overlapping; the latter option can be used to construct segments with nearly arbitrary functional forms, by constructing a Taylor series approximation to the desired functional form and then using a series of overlapping \verb=powerlaw= segments to implement that series.

An example of an advanced mode PDF file is as follows:
\begin{verbatim}
###############################################################
# This is a SFH definition file for SLUG v2.
# This defines a SF history consisting of a series of
# exponentially-decaying bursts with a period of 100 Myr and
# a decay timescale of 10 Myr, with an amplitude chosen to
# give a mean SFR of 10^-2 Msun/yr.
###############################################################

# Declare that this is an advanced mode file
advanced

# First exponential burst
segment
type exponential
min      0.0
max      1.0e8         # Go to 100 Myr
weight   1.0e6         # Form 10^6 Msun of stars over 100 Myr
scale	   1.0e7         # Decay time 10 Myr

# Next 4 bursts
segment
type exponential
min      1.0e8
max      2.0e8
weight   1.0e6
scale	   1.0e7

segment
type exponential
min      2.0e8
max      3.0e8
weight   1.0e6
scale	   1.0e7

segment
type exponential
min      3.0e8
max      4.0e8
weight   1.0e6
scale	   1.0e7

segment
type exponential
min      4.0e8
max      5.0e8
weight   1.0e6
scale	   1.0e7
\end{verbatim}
This represents a star formation history that is a series of exponential bursts, separated by 100 Myr, with decay times of 10 Myr. Formally, this SFH follows the functional form
\begin{equation}
\dot{M}_* = n e^{-(t\,\mathrm{mod}\, P)/t_{\rm dec}},
\end{equation}
where $P = 100$ Myr is the period and $t_{\rm dec} = 10$ Myr is the decay time, from times $0-500$ Myr. The normalization constant $n$ is set by the condition that $(1/P) \int_0^P \dot{M}_* \,dt / = 0.01$ $M_\odot$ yr$^{-1}$, i.e., that the mean SFR averaged over a single burst period is 0.01 $M_\odot$ yr$^{-1}$.

Formally, the format of an advanced mode file is as follows. First, all advanced mode files must start with the line
\begin{verbatim}
advanced
\end{verbatim}
to declare that the file is in advanced mode. After that, there must be a series of entries of the form
\begin{verbatim}
segment
type TYPE
min MIN
max MAX
weight WEIGHT
key1 VAL1
key2 VAL2
...
\end{verbatim}
The \verb=type= keyword is exactly the same as in basic mode, as are the segment-specific parameter keywords \verb=key1=, \verb=key2=, $\ldots$. The same functional forms, listed in Table \ref{tab:segtypes}, are available as in basic mode. The additional keywords that must be supplied in advanced mode are \verb=min=, \verb=max=, and \verb=weight=. The \verb=min= and \verb=max= keywords give the upper and lower limits $x_{i,a}$ and $x_{i,b}$ for the segment; the probability is zero outside these limits. The keyword \verb=weight= specifies the integral under the segment, i.e., the weight $w_i$ given for segment $i$ is used to set the normalization $n_i$ via the equation
\begin{equation}
w_i = n_i \int_{x_{i,a}}^{x_{i,b}} f_i(x) \, dx.
\end{equation}
In the case of a star formation history, as in the example above, the weight $w_i$ of a segment is simply the total mass of stars formed in that segment. In the example given above, the first segment declaration sets up a PDF that with a minimum at 0 Myr, a maximum at 100 Myr, following an exponential functional form with a decay time of $10^7$ yr. During this time, a total mass of $10^6$ $M_\odot$ of stars is formed.

Note that, for the IMF, CMF, and CLF, the absolute values of the weights to not matter, only their relative values. On the other hand, for the SFH, the absolute weight does matter.


\subsection{Sampling Methods}

A final option allowed in both basic and advanced mode is a specification of the sampling method. The sampling method is a description of how to draw a population of objects from the PDF, when the population is specified as having a total sum $M_{\rm target}$ (usually but not necessarily a total mass) rather than a total number of members $N$; there are a number of ways to do this, which do not necessarily yield identical distributions, even for the same underlying PDF. To specify a sampling method, simply add the line
\begin{verbatim}
method METHOD
\end{verbatim}
to the PDF file. This line can appear anywhere except inside a \verb=segment= specification, or before the \verb=breakpoints= or \verb=advanced= line that begins the file. The following values are allowed for \verb=METHOD= (case-insensitive, as always):
\begin{itemize}
\item \texttt{stop\_nearest}: this is the default option: draw until the total mass of the population exceeds $M_{\rm target}$. Either keep or exclude the final star drawn depending on which choice brings the total mass closer to the target value.
\item \texttt{stop\_before}: same as \texttt{stop\_nearest}, but the final object drawn is always excluded.
\item \texttt{stop\_after}: same as \texttt{stop\_nearest}, but the final object drawn is always kept.
\item \texttt{stop\_50}: same as \texttt{stop\_nearest}, but keep or exclude the final object with 50\% probability regardless of which choice gets closer to the target.
\item \texttt{number}: draw exactly $N = M_{\rm target}/\langle M\rangle$ object, where $\langle M\rangle$ is the expectation value for a single draw.
\item \texttt{poisson}: draw exactly $N$ objects, where the value of $N$ is chosen from a Poisson distribution with expectation value $\langle N \rangle = M_{\rm target}/\langle M\rangle$
\item \texttt{sorted\_sampling}: this method was introduced by Weidner \& Kroupa (2006, MNRAS. 365, 1333), and proceeds in steps. One first draws exactly $N= M_{\rm target}/\langle M\rangle$ as in the \texttt{number} method. If the resulting total mass $M_{\rm pop}$ is less than $M_{\rm target}$, the procedure is repeated recursively using a target mass $M_{\rm target} - M_{\rm pop}$ until $M_{\rm pop} > M_{\rm target}$. Finally, one sorts the resulting stellar list from least to most massive, and then keeps or removes the final, most massive star using a \texttt{stop\_nearest} policy. 
\end{itemize}
See the file \texttt{lib/imf/wk06.imf} for an example of a PDF file with a \verb=method= specification.

\section{Output Files and Format}
\label{sec:output}

\Slug\ can produce 7 output files, though the actual number produced depends on the setting for the \verb=out_*= keywords in the parameter file. The only file that is always produced is the summary file, which is named \texttt{MODEL\_NAME\_summary.txt}, where \texttt{MODEL\_NAME} is the value given by the \verb=model_name= keyword in the parameter file. This file contains some basic summary information for the run, and is always formatted as ASCII text regardless of the output format requested.

The other six output files all have names of the form \texttt{MODEL\_NAME\_xxx.ext}, where the extension \texttt{.ext} is one of \texttt{.txt}, \texttt{.bin}, or \texttt{.fits} depending on the \verb=output_mode= specified in the parameter file, and \verb=xxx= is \texttt{integrated\_prop}, \texttt{integrated\_spec}, \texttt{integrated\_phot}, \texttt{cluster\_prop}, \texttt{cluster\_spec}, or \texttt{cluster\_phot}. The production of these output files is controlled by the parameters \verb=out_integrated=, \verb=out_integrated_spec=, \verb=out_integrated_phot=, \verb=out_cluster=, \verb=out_cluster_spec=, and \verb=out_cluster_phot= in the parameter file. The files are formatted as described below. 

The following conventions are used throughout, unless noted otherwise:
\begin{itemize}
\item Masses are in $M_\odot$
\item Times in year
\item Wavelengths are in {\AA}ngstrom
\item Specific luminosities are in erg s$^{-1}$ \AA$^{-1}$
\item For \verb=binary= outputs, variable types refer to c++ types
\end{itemize}

\subsection{The \texttt{integrated\_prop} File}

This file contains data on the bulk physical properties of the galaxy as a whole. It consists of a series of entries containing the following fields:
\begin{itemize}
\item \verb=Time=: evolution time at which the output is produced
\item \verb=TargetMass=: target mass of stars in the galaxy up that time, if the IMF and SFH were perfectly sampled
\item \verb=ActualMass=: actual mass of stars produced in the galaxy up to that time; generally not exactly equal to \verb=TargetMass= due to finite sampling of the IMF and SFH
\item \verb=LiveMass=: actual mass of stars produced in the galaxy up to that time, and which have not yet reached the end of their lives (as marked by the final entry in the stellar evolution tracks)
\item \verb=ClusterMass=: actual mass of stars produced in the galaxy up to that time that are still members of non-disrupted clusters
\item \verb=NumClusters=: number of non-disrupted clusters present in the galaxy at this time
\item \verb=NumDisClust=: number of disrupted clusters present in the galaxy at this time
\item \verb=NumFldStars=: number of field stars present in the galaxy at this time; this count only includes those stars being treated stochastically (see the parameter \verb=min_stoch_mass= in Section \ref{ssec:phys_keywords})
\end{itemize}

If \verb=output_mode= is \verb=ascii=, these data are output in a series of columns, with different trials separated by lines of dashes. If \verb=output_mode= is \verb=fits=, the data are stored as a FITS binary table extension, with one column for each of the variables above, plus an additional column giving the trial number for that entry. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

For \verb=binary= output, the file consists of a series of records containing the following variables
\begin{itemize}
\item \verb=Time= (\verb=double=)
\item \verb=TargetMass= (\verb=double=)
\item \verb=ActualMass= (\verb=double=)
\item \verb=LiveMass= (\verb=double=)
\item \verb=ClusterMass= (\verb=double=)
\item \verb=NumClusters= (\verb=std::vector<double>::size_type=, usually \verb=unsigned long long=)
\item \verb=NumDisClust= (\verb=std::vector<double>::size_type=, usually \verb=unsigned long long=)
\item \verb=NumFldStars= (\verb=std::vector<double>::size_type=, usually \verb=unsigned long long=)
\end{itemize}
There is one record of this form for each output time, with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial.


\subsection{The \texttt{integrated\_spec} File}

This file contains data on the spectra of the entire galaxy, and consists of a series of entries containing the following fields:
\begin{itemize}
\item \verb=Time=: evolution time at which the output is produced
\item \verb=Wavelength=: observed frame wavelength at which the spectrum is evaluated
\item \verb=L_lambda=: specific luminosity at the specified wavelength
\end{itemize}

If \verb=output_mode= is \verb=ascii=, these data are output in a series of columns, with different trials separated by lines of dashes. If \verb=output_mode= is \verb=fits=, the output FITS file has two binary table extensions. The first table contains a single field listing the wavelengths at which the spectra are given. The second table has three fields, giving the trial number, the time, and the spectrum \verb=L_lambda= at that time. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

For binary output, the file is formatted as follows. The file starts with
\begin{itemize}
\item \verb=NWavelength= (\verb=std::vector<double>::size_type=, usually \verb=unsigned long long=): the number of wavelength entries in the spectra
\item \verb=Wavelength= (\verb=NWavelength= entries of type \verb=double=)
\end{itemize}
and then contains a series of records in the format
\begin{itemize}
\item \verb=Time= (\verb=double=)
\item \verb=L_lambda= (\verb=NWavelength= entries of type \verb=double=)
\end{itemize}
There is one such record for each output time, with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial.

\subsection{The \texttt{integrated\_phot} File}

This file contains data on the photometric properties of the entire galaxy, and consists of a series of entries containing the following fields:
\begin{itemize}
\item \verb=Time=: evolution time at which the output is produced
\item \verb=PhotFilter1=: photometric value through filter 1, where filters follow the order in which they are specified by the \verb=phot_bands= keyword; units depend on the value of \verb=phot_mode= (see Section \ref{ssec:phot_keywords})
\item \verb=PhotFilter2=
\item \verb=PhotFilter3=
\item \verb=...=
\end{itemize}

If \verb=output_mode= is \verb=ascii=, these data are output in a series of columns, with different trials separated by lines of dashes. If \verb=output_mode= is \verb=fits=, the data are stored as a series of columns in a binary table extension to the FITS file; the filter names and units are included in the header information for the columns. In addition to the time and photometric filter values, the FITS file contains a column specifying the trial number for that entry. Both the ASCII- and FITS-formatted output should be fairly self-documenting.
 
For binary output, the file is formatted as follows. The file starts with
\begin{itemize}
\item \verb=NFilter= (stored as \verb=ASCII text=): number of filters used
\item \verb=FilterName= \verb=FilterUnit= (\verb=NFilter= entries stored as \verb=ASCII text=): the name and units for each filter are listed in ASCII, one filter-unit pair per line
\end{itemize}
This is followed by a series of entries of the form
\begin{itemize}
\item \verb=Time= (\verb=double=)
\item \verb=PhotFilter= (\verb=NFilter= entries of type \verb=double=)
\end{itemize}
There is one such record for each output time, with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial.

\subsection{The \texttt{cluster\_prop} File}

This file contains data on the bulk physical properties of the non-disrupted star clusters in the galaxy, with one entry per cluster per time at which that cluster exists. Each entry contains the following fields
\begin{itemize}
\item \verb=UniqueID=: a unique identifier number for each cluster that is preserved across times and output files
\item \verb=Time=: evolution time at which the output is produced
\item \verb=FormTime=: time at which that cluster formed
\item \verb=Lifetime=: amount of time from birth to when the cluster will disrupt
\item \verb=TargetMass=: target mass of stars in the cluster, if the IMF were perfectly sampled
\item \verb=BirthMass=: actual mass of stars present in the cluster at formation
\item \verb=LiveMass=: actual mass of stars produced in the cluster at this output time that have not yet reached the end of their lives (as marked by the final entry in the stellar evolution tracks)
\item \verb=NumStar=: number of living stars in the cluster at this time; this count only includes those stars being treated stochastically (see the parameter \verb=min_stoch_mass= in Section \ref{ssec:phys_keywords})
\item \verb=MaxStarMass=: mass of most massive star still living in the cluster; this only includes those stars being treated stochastically (see the parameter \verb=min_stoch_mass= in Section \ref{ssec:phys_keywords})
\end{itemize}

If \verb=output_mode= is \verb=ascii=, these data are output in a series of columns, with different trials separated by lines of dashes. If \verb=output_mode= is \verb=fits=, the data are stored as a FITS binary table extension, with one column for each of the variables above, plus an additional column giving the trial number for that entry. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

For \verb=binary= output, the file consists of a series of records, one for each output time, with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial. Each record consists of a header containing
\begin{itemize}
\item \verb=Time= (\verb=double=)
\item \verb=NCluster= (\verb=std::vector<double>::size_type=, usually \verb=unsigned long long=): number of non-disrupted clusters present at this time
\end{itemize}
This is followed by \verb=NCluster= entries of the following form:
\begin{itemize}
\item \verb=UniqueID= (\verb=unsigned long=)
\item \verb=FormationTime= (\verb=double=)
\item \verb=Lifetime= (\verb=double=)
\item \verb=TargetMass= (\verb=double=)
\item \verb=BirthMass= (\verb=double=)
\item \verb=LiveMass= (\verb=double=)
\item \verb=NumStar= (\verb=std::vector<double>::size_type=, usually \verb=unsigned long long=)
\item \verb=MaxStarMass= (\verb=double=)
\end{itemize}

\subsection{The \texttt{cluster\_spec} File}

This file contains the spectra of the individual clusters, and each entry contains the following fields:
\begin{itemize}
\item \verb=UniqueID=: a unique identifier number for each cluster that is preserved across times and output files
\item \verb=Time=: evolution time at which the output is produced
\item \verb=Wavelength=: observed frame wavelength at which the spectrum is evaluated
\item \verb=L_lambda=: specific luminosity at the specified wavelength
\end{itemize}

If \verb=output_mode= is \verb=ascii=, these data are output in a series of columns, with different trials separated by lines of dashes. If \verb=output_mode= is \verb=fits=, the output FITS file has two binary table extensions. The first table contains a single field listing the wavelengths at which the spectra are given. The second table has four fields, giving the trial number, the unique ID of the cluster, the time, and the spectrum \verb=L_lambda=. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

Output in \verb=binary= mode is formatted as follows.  The file starts with
\begin{itemize}
\item \verb=NWavelength= (\verb=std::vector<double>::size_type=, usually \verb=unsigned long long=): the number of wavelength entries in the spectra
\item \verb=Wavelength= (\verb=NWavelength= entries of type \verb=double=)
\end{itemize}
and then contains a series of records, one for each output time , with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial. Each record consists of a header containing
\begin{itemize}
\item \verb=Time= (\verb=double=)
\item \verb=NCluster= (\verb=std::vector<double>::size_type=, usually \verb=unsigned long long=): number of non-disrupted clusters present at this time
\end{itemize}
This is followed by \verb=NCluster= entries of the following form:
\begin{itemize}
\item \verb=UniqueID= (\verb=unsigned long=)
\item \verb=L_lambda= (\verb=NWavelength= entries of type \verb=double=)
\end{itemize}

\subsection{The \texttt{cluster\_phot} File}

This file contains the photometric values for the individual clusters. Each entry contains the following fields:
\begin{itemize}
\item \verb=UniqueID=: a unique identifier number for each cluster that is preserved across times and output files
\item \verb=Time=: evolution time at which the output is produced
\item \verb=PhotFilter1=: photometric value through filter 1, where filters follow the order in which they are specified by the \verb=phot_bands= keyword; units depend on the value of \verb=phot_mode= (see Section \ref{ssec:phot_keywords})
\item \verb=PhotFilter2=
\item \verb=PhotFilter3=
\item \verb=...=
\end{itemize}

If \verb=output_mode= is \verb=ascii=, these data are output in a series of columns, with different trials separated by lines of dashes. If \verb=output_mode= is \verb=fits=, the data are stored as a series of columns in a binary table extension to the FITS file; the filter names and units are included in the header information for the columns. In addition to the time, unique ID, and photometric filter values, the FITS file contains a column specifying the trial number for that entry. Both the ASCII- and FITS-formatted output should be fairly self-documenting.

In \verb=binary= output mode, the binary data file starts with
\begin{itemize}
\item \verb=NFilter= (stored as \verb=ASCII text=): number of filters used
\item \verb=FilterName= \verb=FilterUnit= (\verb=NFilter= entries stored as \verb=ASCII text=): the name and units for each filter are listed in ASCII, one filter-unit pair per line
\end{itemize}
and then contains a series of records, one for each output time , with different trials ordered sequentially, so that all the times for one trial are output before the first time for the next trial. Each record consists of a header containing
\begin{itemize}
\item \verb=Time= (\verb=double=)
\item \verb=NCluster= (\verb=std::vector<double>::size_type=, usually \verb=unsigned long long=): number of non-disrupted clusters present at this time
\end{itemize}
This is followed by \verb=NCluster= entries of the following form:
\begin{itemize}
\item \verb=UniqueID= (\verb=unsigned long=)
\item \verb=PhotFilter= (\verb=NFilter= entries of type \verb=double=)
\end{itemize}

\section{Filter Data}

\Slug\ comes with a fairly extensive list of filters, adapted from the list maintained by Charlie Conroy as part of \href{https://code.google.com/p/fsps/}{fsps}. However, users may wish to add additional filters, and so the format of the filter list is documented here for convenience.

Filter data is stored in two ASCII text files, \verb=FILTER_LIST= and \verb=allfilters.dat=, which are stored in the \verb=lib/filters= directory. The \verb=FILTER_LIST= file is an index listing the available filters. In consists of five whitespace-separated columns. The first column is just an numerical index. The second is the name of the filter; this is the name that should be entered in the \verb=phot_bands= keyword (see Section \ref{ssec:phot_keywords}) to request photometry in that filter. The third and fourth columns the value of $\beta$ and $\lambda_c$ (the central wavelength) for that filter -- see \ref{ssec:spec_phot} for definitions. Anything after the fourth column is regarded as a comment, and can be used freely for a description of that filter.

The \verb=allfilters.dat= file contains the filter responses. The file contains a series of entires for different filters, each delineated by a header line that begins with \verb=#=. The order in which filters appear in this file matches that in which they appear in the \verb=FILTER_LIST=. After the header line, are a series of lines each containing two numbers. The first is the wavelength in {\AA}ngstrom, and the second is the filter response function at that wavelength.

\section{\slugpy\ -- The Python Helper Library}



\section{Test Problems}
\label{sec:test}

This section describes a set of problems that can be used to test and explore the different 
capabilities of \slug. \slug\ ships a set of problems \verb=problemname= that are specified by a 
parameter file \verb=param/problemname.param=. Users can reproduce the output of the test 
problems with the following command: \verb=./bin/slug param/problemname.param=.
For each problem, a script for analysis is distributed in \verb=test/problemname.py=. 
Specific information for each test problem are given below. 

\subsection{Problem {\tt example}: basic galaxy simulation}

This problem illustrates the basic usage of \slug\ in \verb=galaxy= mode. 

[simple run]

\subsection{Problem {\tt example\_cluster}: basic cluster simulation}

This problem illustrates the basic usage of \slug\ in \verb=cluster= mode. 

[simple run]

\subsection{Problem {\tt sfrstochastic}: stochastic star formation}

This problem highlights the relevance of stochastic star formation in \slug, in
comparison to deterministic codes.

[show the scatter in a quantity relative to the 'mean' deterministic value]

\subsection{Problem {\tt sfhsampling}: realizations of SFH}

This problem illustrates the conceptual difference between an input SFH and the effective 
realizations produced by \slug, in comparison to deterministic codes.

[show how a input SFH gets implemented in different realizations]

\subsection{Problem {\tt constsampl}: importance of constrained sampling}

This problem illustrates the effects of constrained sampling on the realization of an 
input IMF.

[change cluster mass to show how max mass changes]


\subsection{Problem {\tt sampling}: different sampling techniques}

This problem highlights the flexible choice of sampling techniques in \slug, which is 
a new capability of v2.

[basic run with different sampling]


\subsection{Problem {\tt imfchoice}: different IMF implementations}

This problem highlights the flexible choice of IMF implementations in \slug.

[basic run with different imfs]

\subsection{Problem {\tt cmfchoice}: different CMF implementations}

This problem highlights the flexible choice of CMF implementations in \slug.

[basic run with different cmfs]


\subsection{Problem {\tt cldisrupt}: cluster disruption at work}

This problem highlights the flexible choice of CLF implementations in \slug.

[basic run with different clfs]


\subsection{Problem {\tt clfraction}: cluster fraction at work}

This problem highlights the flexible choice of cluster fraction during \slug\ simulations.

[basic run with different fc]

\subsection{Problem {\tt spectra}: full spectra}

This problem highlights the power of the new feature offered in \slug\ v2: the ability to produce 
full spectra. 

[basic run with full spectra out: shows stochasticity applied to spectra]

\subsection{Problem {\tt redshift}: trivial redshift example}

This problem shows a trivial example of the redshift capability in \slug\ v2.

[basic run with full spectra out at a different redshift]




\end{document}
